<!DOCTYPE html><html>
<head><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<link rel="stylesheet" href="styles/intel_table_styles.css"></head>
<body>
<h3>Intel&reg; Microarchitecture Code Named Skylake-X Events</h3> This section provides reference for hardware events that can be monitored for the CPU(s):<p>
<li>Intel&reg; Microarchitecture Code Named Skylake-X</li><p>
<table class="table table-responsive" style="table-layout:fixed;width:100%">
	<tr>
		<th>EventName</th>
		<th>Description</th>
	</tr>
	<tr>
		<td><span id="INST_RETIRED.ANY">INST_RETIRED.ANY</span></td>
		<td>Counts the number of instructions retired from execution. For instructions that consist of multiple micro-ops, Counts the retirement of the last micro-op of the instruction. Counting continues during hardware interrupts, traps, and inside interrupt handlers. Notes: INST_RETIRED.ANY is counted by a designated fixed counter, leaving the four (eight when Hyperthreading is disabled) programmable counters available for other events. INST_RETIRED.ANY_P is counted by a programmable counter and it is an architectural performance event. Counting: Faulting executions of GETSEC/VM entry/VM Exit/MWait will not count as retired instructions.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.THREAD">CPU_CLK_UNHALTED.THREAD</span></td>
		<td>Counts the number of core cycles while the thread is not in a halt state. The thread enters the halt state when it is running the HLT instruction. This event is a component in many key event ratios. The core frequency may change from time to time due to transitions associated with Enhanced Intel SpeedStep Technology or TM2. For this reason this event may have a changing ratio with regards to time. When the core frequency is constant, this event can approximate elapsed time while the core was not in the halt state. It is counted on a dedicated fixed counter, leaving the four (eight when Hyperthreading is disabled) programmable counters available for other events.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.REF_TSC">CPU_CLK_UNHALTED.REF_TSC</span></td>
		<td>Counts the number of reference cycles when the core is not in a halt state. The core enters the halt state when it is running the HLT instruction or the MWAIT instruction. This event is not affected by core frequency changes (for example, P states, TM2 transitions) but has the same incrementing frequency as the time stamp counter. This event can approximate elapsed time while the core was not in a halt state. This event has a constant ratio with the CPU_CLK_UNHALTED.REF_XCLK event. It is counted on a dedicated fixed counter, leaving the four (eight when Hyperthreading is disabled) programmable counters available for other events. Note: On all current platforms this event stops counting during &#39;throttling (TM)&#39; states duty off periods the processor is &#39;halted&#39;.  The counter update is done at a lower clock rate then the core clock the overflow status bit for this counter may appear &#39;sticky&#39;.  After the counter has overflowed and software clears the overflow status bit and resets the counter to less than MAX. The reset value to the counter is not clocked immediately so the overflow status bit will flip &#39;high (1)&#39; and generate another PMI (if enabled) after which the reset value gets clocked into the counter. Therefore, software will get the interrupt, read the overflow status bit &#39;1 for bit 34 while the counter value is less than MAX. Software should ignore this case.</td>
	</tr>
	<tr>
		<td><span id="ICACHE_16B.IFDATA_STALL">ICACHE_16B.IFDATA_STALL</span></td>
		<td>Cycles where a code line fetch is stalled due to an L1 instruction cache miss. The legacy decode pipeline works at a 16 Byte granularity.</td>
	</tr>
	<tr>
		<td><span id="ICACHE_64B.IFTAG_HIT">ICACHE_64B.IFTAG_HIT</span></td>
		<td>Instruction fetch tag lookups that hit in the instruction cache (L1I). Counts at 64-byte cache-line granularity.</td>
	</tr>
	<tr>
		<td><span id="ICACHE_64B.IFTAG_MISS">ICACHE_64B.IFTAG_MISS</span></td>
		<td>Instruction fetch tag lookups that miss in the instruction cache (L1I). Counts at 64-byte cache-line granularity.</td>
	</tr>
	<tr>
		<td><span id="ICACHE_64B.IFTAG_STALL">ICACHE_64B.IFTAG_STALL</span></td>
		<td>Cycles where a code fetch is stalled due to L1 instruction cache tag miss.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.THREAD_P">CPU_CLK_UNHALTED.THREAD_P</span></td>
		<td>This is an architectural event that counts the number of thread cycles while the thread is not in a halt state. The thread enters the halt state when it is running the HLT instruction. The core frequency may change from time to time due to power or thermal throttling. For this reason, this event may have a changing ratio with regards to wall clock time.</td>
	</tr>
	<tr>
		<td><span id="BACLEARS.ANY">BACLEARS.ANY</span></td>
		<td>Counts the number of times the front-end is resteered when it finds a branch instruction in a fetch line. This occurs for the first time a branch instruction is fetched or when the branch is not tracked by the BPU (Branch Prediction Unit) anymore.</td>
	</tr>
	<tr>
		<td><span id="ITLB.ITLB_FLUSH">ITLB.ITLB_FLUSH</span></td>
		<td>Counts the number of flushes of the big or small ITLB pages. Counting include both TLB Flush (covering all sets) and TLB Set Clear (set-specific).</td>
	</tr>
	<tr>
		<td><span id="LSD.UOPS">LSD.UOPS</span></td>
		<td>Number of uops delivered to the back-end by the LSD(Loop Stream Detector).</td>
	</tr>
	<tr>
		<td><span id="ILD_STALL.LCP">ILD_STALL.LCP</span></td>
		<td>Counts cycles that the Instruction Length decoder (ILD) stalls occurred due to dynamically changing prefix length of the decoded instruction (by operand size prefix instruction 0x66, address size prefix instruction 0x67 or REX.W for Intel64). Count is proportional to the number of prefixes in a 16B-line. This may result in a three-cycle penalty for each LCP (Length changing prefix) in a 16-byte chunk.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MITE_UOPS">IDQ.MITE_UOPS</span></td>
		<td>Counts the number of uops delivered to Instruction Decode Queue (IDQ) from the MITE path. Counting includes uops that may &#39;bypass&#39; the IDQ. This also means that uops are not being delivered from the Decode Stream Buffer (DSB).</td>
	</tr>
	<tr>
		<td><span id="IDQ.DSB_UOPS">IDQ.DSB_UOPS</span></td>
		<td>Counts the number of uops delivered to Instruction Decode Queue (IDQ) from the Decode Stream Buffer (DSB) path. Counting includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MS_MITE_UOPS">IDQ.MS_MITE_UOPS</span></td>
		<td>Counts the number of uops initiated by MITE and delivered to Instruction Decode Queue (IDQ) while the Microcode Sequencer (MS) is busy. Counting includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MS_CYCLES">IDQ.MS_CYCLES</span></td>
		<td>Counts cycles during which uops are being delivered to Instruction Decode Queue (IDQ) while the Microcode Sequencer (MS) is busy. Counting includes uops that may &#39;bypass&#39; the IDQ. Uops maybe initiated by Decode Stream Buffer (DSB) or MITE.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MITE_CYCLES">IDQ.MITE_CYCLES</span></td>
		<td>Counts cycles during which uops are being delivered to Instruction Decode Queue (IDQ) from the MITE path. Counting includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.DSB_CYCLES">IDQ.DSB_CYCLES</span></td>
		<td>Counts cycles during which uops are being delivered to Instruction Decode Queue (IDQ) from the Decode Stream Buffer (DSB) path. Counting includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MS_DSB_CYCLES">IDQ.MS_DSB_CYCLES</span></td>
		<td>Counts cycles during which uops initiated by Decode Stream Buffer (DSB) are being delivered to Instruction Decode Queue (IDQ) while the Microcode Sequencer (MS) is busy. Counting includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.ALL_DSB_CYCLES_4_UOPS">IDQ.ALL_DSB_CYCLES_4_UOPS</span></td>
		<td>Counts the number of cycles 4 uops were delivered to Instruction Decode Queue (IDQ) from the Decode Stream Buffer (DSB) path. Count includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.ALL_DSB_CYCLES_ANY_UOPS">IDQ.ALL_DSB_CYCLES_ANY_UOPS</span></td>
		<td>Counts the number of cycles uops were delivered to Instruction Decode Queue (IDQ) from the Decode Stream Buffer (DSB) path. Count includes uops that may &#39;bypass&#39; the IDQ.</td>
	</tr>
	<tr>
		<td><span id="IDQ.ALL_MITE_CYCLES_4_UOPS">IDQ.ALL_MITE_CYCLES_4_UOPS</span></td>
		<td>Counts the number of cycles 4 uops were delivered to the Instruction Decode Queue (IDQ) from the MITE (legacy decode pipeline) path. Counting includes uops that may &#39;bypass&#39; the IDQ. During these cycles uops are not being delivered from the Decode Stream Buffer (DSB).</td>
	</tr>
	<tr>
		<td><span id="IDQ.ALL_MITE_CYCLES_ANY_UOPS">IDQ.ALL_MITE_CYCLES_ANY_UOPS</span></td>
		<td>Counts the number of cycles uops were delivered to the Instruction Decode Queue (IDQ) from the MITE (legacy decode pipeline) path. Counting includes uops that may &#39;bypass&#39; the IDQ. During these cycles uops are not being delivered from the Decode Stream Buffer (DSB).</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CORE">IDQ_UOPS_NOT_DELIVERED.CORE</span></td>
		<td>Counts the number of uops not delivered to Resource Allocation Table (RAT) per thread adding “4 – x” when Resource Allocation Table (RAT) is not stalled and Instruction Decode Queue (IDQ) delivers x uops to Resource Allocation Table (RAT) (where x belongs to {0,1,2,3}). Counting does not cover cases when: a. IDQ-Resource Allocation Table (RAT) pipe serves the other thread. b. Resource Allocation Table (RAT) is stalled for the thread (including uop drops and clear BE conditions).  c. Instruction Decode Queue (IDQ) delivers four uops.</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CYCLES_0_UOPS_DELIV.CORE">IDQ_UOPS_NOT_DELIVERED.CYCLES_0_UOPS_DELIV.CORE</span></td>
		<td>Counts, on the per-thread basis, cycles when no uops are delivered to Resource Allocation Table (RAT). IDQ_Uops_Not_Delivered.core =4.</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_1_UOP_DELIV.CORE">IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_1_UOP_DELIV.CORE</span></td>
		<td>Counts, on the per-thread basis, cycles when less than 1 uop is delivered to Resource Allocation Table (RAT). IDQ_Uops_Not_Delivered.core &gt;= 3.</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_2_UOP_DELIV.CORE">IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_2_UOP_DELIV.CORE</span></td>
		<td>Cycles with less than 2 uops delivered by the front-end.</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_3_UOP_DELIV.CORE">IDQ_UOPS_NOT_DELIVERED.CYCLES_LE_3_UOP_DELIV.CORE</span></td>
		<td>Cycles with less than 3 uops delivered by the front-end.</td>
	</tr>
	<tr>
		<td><span id="IDQ_UOPS_NOT_DELIVERED.CYCLES_FE_WAS_OK">IDQ_UOPS_NOT_DELIVERED.CYCLES_FE_WAS_OK</span></td>
		<td>Counts cycles FE delivered 4 uops or Resource Allocation Table (RAT) was stalling FE.</td>
	</tr>
	<tr>
		<td><span id="DSB2MITE_SWITCHES.COUNT">DSB2MITE_SWITCHES.COUNT</span></td>
		<td>This event counts the number of the Decode Stream Buffer (DSB)-to-MITE switches including all misses because of missing Decode Stream Buffer (DSB) cache and u-arch forced misses.
Note: Invoking MITE requires two or three cycles delay.</td>
	</tr>
	<tr>
		<td><span id="DSB2MITE_SWITCHES.PENALTY_CYCLES">DSB2MITE_SWITCHES.PENALTY_CYCLES</span></td>
		<td>Counts Decode Stream Buffer (DSB)-to-MITE switch true penalty cycles. These cycles do not include uops routed through because of the switch itself, for example, when Instruction Decode Queue (IDQ) pre-allocation is unavailable, or Instruction Decode Queue (IDQ) is full. SBD-to-MITE switch true penalty cycles happen after the merge mux (MM) receives Decode Stream Buffer (DSB) Sync-indication until receiving the first MITE uop. MM is placed before Instruction Decode Queue (IDQ) to merge uops being fed from the MITE and Decode Stream Buffer (DSB) paths. Decode Stream Buffer (DSB) inserts the Sync-indication whenever a Decode Stream Buffer (DSB)-to-MITE switch occurs.Penalty: A Decode Stream Buffer (DSB) hit followed by a Decode Stream Buffer (DSB) miss can cost up to six cycles in which no uops are delivered to the IDQ. Most often, such switches from the Decode Stream Buffer (DSB) to the legacy pipeline cost 0–2 cycles.</td>
	</tr>
	<tr>
		<td><span id="INT_MISC.RECOVERY_CYCLES">INT_MISC.RECOVERY_CYCLES</span></td>
		<td>Core cycles the Resource allocator was stalled due to recovery from an earlier branch misprediction or machine clear event.</td>
	</tr>
	<tr>
		<td><span id="INT_MISC.CLEAR_RESTEER_CYCLES">INT_MISC.CLEAR_RESTEER_CYCLES</span></td>
		<td>Cycles the issue-stage is waiting for front-end to fetch from resteered path following branch misprediction or machine clear events.</td>
	</tr>
	<tr>
		<td><span id="PARTIAL_RAT_STALLS.SCOREBOARD">PARTIAL_RAT_STALLS.SCOREBOARD</span></td>
		<td>This event counts cycles during which the microcode scoreboard stalls happen.</td>
	</tr>
	<tr>
		<td><span id="RESOURCE_STALLS.ANY">RESOURCE_STALLS.ANY</span></td>
		<td>Counts resource-related stall cycles.</td>
	</tr>
	<tr>
		<td><span id="RESOURCE_STALLS.SB">RESOURCE_STALLS.SB</span></td>
		<td>Counts allocation stall cycles caused by the store buffer (SB) being full. This counts cycles that the pipeline back-end blocked uop delivery from the front-end.</td>
	</tr>
	<tr>
		<td><span id="UOPS_ISSUED.ANY">UOPS_ISSUED.ANY</span></td>
		<td>Counts the number of uops that the Resource Allocation Table (RAT) issues to the Reservation Station (RS).</td>
	</tr>
	<tr>
		<td><span id="UOPS_ISSUED.SLOW_LEA">UOPS_ISSUED.SLOW_LEA</span></td>
		<td>Number of slow LEA uops being allocated. A uop is generally considered SlowLea if it has 3 sources (e.g. 2 sources + immediate) regardless if as a result of LEA instruction or not.</td>
	</tr>
	<tr>
		<td><span id="UOPS_ISSUED.STALL_CYCLES">UOPS_ISSUED.STALL_CYCLES</span></td>
		<td>Counts cycles during which the Resource Allocation Table (RAT) does not issue any Uops to the reservation station (RS) for the current thread.</td>
	</tr>
	<tr>
		<td><span id="TX_EXEC.MISC1">TX_EXEC.MISC1</span></td>
		<td>Counts the number of times a class of instructions that may cause a transactional abort was executed. Since this is the count of execution, it may not always cause a transactional abort.</td>
	</tr>
	<tr>
		<td><span id="TX_EXEC.MISC2">TX_EXEC.MISC2</span></td>
		<td>Unfriendly TSX abort triggered by a vzeroupper instruction.</td>
	</tr>
	<tr>
		<td><span id="TX_EXEC.MISC3">TX_EXEC.MISC3</span></td>
		<td>Unfriendly TSX abort triggered by a nest count that is too deep.</td>
	</tr>
	<tr>
		<td><span id="TX_EXEC.MISC4">TX_EXEC.MISC4</span></td>
		<td>RTM region detected inside HLE.</td>
	</tr>
	<tr>
		<td><span id="TX_EXEC.MISC5">TX_EXEC.MISC5</span></td>
		<td>Counts the number of times an HLE XACQUIRE instruction was executed inside an RTM transactional region.</td>
	</tr>
	<tr>
		<td><span id="RS_EVENTS.EMPTY_CYCLES">RS_EVENTS.EMPTY_CYCLES</span></td>
		<td>Counts cycles during which the reservation station (RS) is empty for the thread.; Note: In ST-mode, not active thread should drive 0. This is usually caused by severely costly branch mispredictions, or allocator/FE issues.</td>
	</tr>
	<tr>
		<td><span id="RS_EVENTS.EMPTY_END">RS_EVENTS.EMPTY_END</span></td>
		<td>Counts end of periods where the Reservation Station (RS) was empty. Could be useful to precisely locate front-end Latency Bound issues.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.START">HLE_RETIRED.START</span></td>
		<td>Number of times we entered an HLE region. Does not count nested transactions.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.COMMIT">HLE_RETIRED.COMMIT</span></td>
		<td>Number of times HLE commit succeeded.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED">HLE_RETIRED.ABORTED</span></td>
		<td>Number of times HLE abort was triggered.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_MEM">HLE_RETIRED.ABORTED_MEM</span></td>
		<td>Number of times an HLE execution aborted due to various memory events (e.g., read/write capacity and conflicts).</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_TIMER">HLE_RETIRED.ABORTED_TIMER</span></td>
		<td>Number of times an HLE execution aborted due to hardware timer expiration.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_UNFRIENDLY">HLE_RETIRED.ABORTED_UNFRIENDLY</span></td>
		<td>Number of times an HLE execution aborted due to HLE-unfriendly instructions and certain unfriendly events (such as AD assists etc.).</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_MEMTYPE">HLE_RETIRED.ABORTED_MEMTYPE</span></td>
		<td>Number of times an HLE execution aborted due to incompatible memory type.</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_EVENTS">HLE_RETIRED.ABORTED_EVENTS</span></td>
		<td>Number of times an HLE execution aborted due to unfriendly events (such as interrupts).</td>
	</tr>
	<tr>
		<td><span id="HLE_RETIRED.ABORTED_PS">HLE_RETIRED.ABORTED_PS</span></td>
		<td>Number of times HLE abort was triggered. (PEBS)</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.START">RTM_RETIRED.START</span></td>
		<td>Number of times we entered an RTM region. Does not count nested transactions.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.COMMIT">RTM_RETIRED.COMMIT</span></td>
		<td>Number of times RTM commit succeeded.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED">RTM_RETIRED.ABORTED</span></td>
		<td>Number of times RTM abort was triggered.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_MEM">RTM_RETIRED.ABORTED_MEM</span></td>
		<td>Number of times an RTM execution aborted due to various memory events (e.g. read/write capacity and conflicts).</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_TIMER">RTM_RETIRED.ABORTED_TIMER</span></td>
		<td>Number of times an RTM execution aborted due to uncommon conditions.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_UNFRIENDLY">RTM_RETIRED.ABORTED_UNFRIENDLY</span></td>
		<td>Number of times an RTM execution aborted due to HLE-unfriendly instructions.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_MEMTYPE">RTM_RETIRED.ABORTED_MEMTYPE</span></td>
		<td>Number of times an RTM execution aborted due to incompatible memory type.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_EVENTS">RTM_RETIRED.ABORTED_EVENTS</span></td>
		<td>Number of times an RTM execution aborted due to none of the previous 4 categories (e.g. interrupt).</td>
	</tr>
	<tr>
		<td><span id="ROB_MISC_EVENTS.LBR_INSERTS">ROB_MISC_EVENTS.LBR_INSERTS</span></td>
		<td>Increments when an entry is added to the Last Branch Record (LBR) array (or removed from the array in case of RETURNs in call stack mode). The event requires LBR enable via IA32_DEBUGCTL MSR and branch type selection via MSR_LBR_SELECT.</td>
	</tr>
	<tr>
		<td><span id="MACHINE_CLEARS.COUNT">MACHINE_CLEARS.COUNT</span></td>
		<td>Number of machine clears (nukes) of any type.</td>
	</tr>
	<tr>
		<td><span id="MACHINE_CLEARS.MEMORY_ORDERING">MACHINE_CLEARS.MEMORY_ORDERING</span></td>
		<td>Counts the number of memory ordering Machine Clears detected. Memory Ordering Machine Clears can result from one of the following:a. memory disambiguation,b. external snoop, orc. cross SMT-HW-thread snoop (stores) hitting load buffer.</td>
	</tr>
	<tr>
		<td><span id="MACHINE_CLEARS.SMC">MACHINE_CLEARS.SMC</span></td>
		<td>Counts self-modifying code (SMC) detected, which causes a machine clear.</td>
	</tr>
	<tr>
		<td><span id="HW_INTERRUPTS.RECEIVED">HW_INTERRUPTS.RECEIVED</span></td>
		<td>Counts the number of hardware interruptions received by the processor.</td>
	</tr>
	<tr>
		<td><span id="RTM_RETIRED.ABORTED_PS">RTM_RETIRED.ABORTED_PS</span></td>
		<td>Number of times RTM abort was triggered. (PEBS)</td>
	</tr>
	<tr>
		<td><span id="INST_RETIRED.ANY_P">INST_RETIRED.ANY_P</span></td>
		<td>Counts the number of instructions (EOMs) retired. Counting covers macro-fused instructions individually (that is, increments by two).</td>
	</tr>
	<tr>
		<td><span id="INST_RETIRED.PREC_DIST">INST_RETIRED.PREC_DIST</span></td>
		<td>A version of INST_RETIRED that allows for a more unbiased distribution of samples across instructions retired. It utilizes the Precise Distribution of Instructions Retired (PDIR) feature to mitigate some bias in how retired instructions get sampled.</td>
	</tr>
	<tr>
		<td><span id="UOPS_RETIRED.RETIRE_SLOTS">UOPS_RETIRED.RETIRE_SLOTS</span></td>
		<td>Counts the retirement slots used.</td>
	</tr>
	<tr>
		<td><span id="UOPS_RETIRED.STALL_CYCLES">UOPS_RETIRED.STALL_CYCLES</span></td>
		<td>This event counts cycles without actually retired uops.</td>
	</tr>
	<tr>
		<td><span id="UOPS_RETIRED.TOTAL_CYCLES">UOPS_RETIRED.TOTAL_CYCLES</span></td>
		<td>Number of cycles using always true condition (uops_ret &lt; 16) applied to non PEBS uops retired event.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.CONDITIONAL">BR_INST_RETIRED.CONDITIONAL</span></td>
		<td>This event counts conditional branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_CALL">BR_INST_RETIRED.NEAR_CALL</span></td>
		<td>This event counts both direct and indirect near call instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.ALL_BRANCHES">BR_INST_RETIRED.ALL_BRANCHES</span></td>
		<td>Counts all (macro) branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_RETURN">BR_INST_RETIRED.NEAR_RETURN</span></td>
		<td>This event counts return instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NOT_TAKEN">BR_INST_RETIRED.NOT_TAKEN</span></td>
		<td>This event counts not taken branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_TAKEN">BR_INST_RETIRED.NEAR_TAKEN</span></td>
		<td>This event counts taken branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.FAR_BRANCH">BR_INST_RETIRED.FAR_BRANCH</span></td>
		<td>This event counts far branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.CONDITIONAL_PS">BR_INST_RETIRED.CONDITIONAL_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts conditional branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_CALL_PS">BR_INST_RETIRED.NEAR_CALL_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts both direct and indirect near call instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.ALL_BRANCHES_PS">BR_INST_RETIRED.ALL_BRANCHES_PS</span></td>
		<td>This is a precise version of BR_INST_RETIRED.ALL_BRANCHES that counts all (macro) branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_RETURN_PS">BR_INST_RETIRED.NEAR_RETURN_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts return instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.NEAR_TAKEN_PS">BR_INST_RETIRED.NEAR_TAKEN_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts taken branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.FAR_BRANCH_PS">BR_INST_RETIRED.FAR_BRANCH_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts far branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.CONDITIONAL">BR_MISP_RETIRED.CONDITIONAL</span></td>
		<td>This event counts mispredicted conditional branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.NEAR_CALL">BR_MISP_RETIRED.NEAR_CALL</span></td>
		<td>Counts both taken and not taken retired mispredicted direct and indirect near calls, including both register and memory indirect.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.ALL_BRANCHES">BR_MISP_RETIRED.ALL_BRANCHES</span></td>
		<td>Counts all the retired branch instructions that were mispredicted by the processor. A branch misprediction occurs when the processor incorrectly predicts the destination of the branch.  When the misprediction is discovered at execution, all the instructions executed in the wrong (speculative) path must be discarded, and the processor must start fetching from the correct path.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.NEAR_TAKEN">BR_MISP_RETIRED.NEAR_TAKEN</span></td>
		<td>Number of near branch instructions retired that were mispredicted and taken.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.CONDITIONAL_PS">BR_MISP_RETIRED.CONDITIONAL_PS</span></td>
		<td>This is a precise version (that is, uses PEBS) of the event that counts mispredicted conditional branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.NEAR_CALL_PS">BR_MISP_RETIRED.NEAR_CALL_PS</span></td>
		<td>This event counts both taken and not taken retired mispredicted direct and indirect near calls, including both register and memory indirect.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.ALL_BRANCHES_PS">BR_MISP_RETIRED.ALL_BRANCHES_PS</span></td>
		<td>This is a precise version of BR_MISP_RETIRED.ALL_BRANCHES that counts all mispredicted macro branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="BR_MISP_RETIRED.NEAR_TAKEN_PS">BR_MISP_RETIRED.NEAR_TAKEN_PS</span></td>
		<td>Number of near branch instructions retired that were mispredicted and taken.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.SCALAR_DOUBLE">FP_ARITH_INST_RETIRED.SCALAR_DOUBLE</span></td>
		<td>Number of SSE/AVX computational scalar double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computation. Applies to SSE* and AVX* scalar double precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.SCALAR_SINGLE">FP_ARITH_INST_RETIRED.SCALAR_SINGLE</span></td>
		<td>Number of SSE/AVX computational scalar single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 1 computation. Applies to SSE* and AVX* scalar single precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.128B_PACKED_DOUBLE">FP_ARITH_INST_RETIRED.128B_PACKED_DOUBLE</span></td>
		<td>Number of SSE/AVX computational 128-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 2 computation operations, one for each element.  Applies to SSE* and AVX* packed double precision floating-point instructions: ADD SUB HADD HSUB SUBADD MUL DIV MIN MAX SQRT RSQRT14 RCP14 DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.128B_PACKED_SINGLE">FP_ARITH_INST_RETIRED.128B_PACKED_SINGLE</span></td>
		<td>Number of SSE/AVX computational 128-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations, one for each element.  Applies to SSE* and AVX* packed single precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.256B_PACKED_DOUBLE">FP_ARITH_INST_RETIRED.256B_PACKED_DOUBLE</span></td>
		<td>Number of SSE/AVX computational 256-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 4 computation operations, one for each element.  Applies to SSE* and AVX* packed double precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.256B_PACKED_SINGLE">FP_ARITH_INST_RETIRED.256B_PACKED_SINGLE</span></td>
		<td>Number of SSE/AVX computational 256-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations, one for each element.  Applies to SSE* and AVX* packed single precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 2 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ASSIST.ANY">FP_ASSIST.ANY</span></td>
		<td>Counts cycles with any input and output SSE or x87 FP assist. If an input and output assist are detected on the same cycle the event increments by 1.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_4">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_4</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 4 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_8">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_8</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 8 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_16">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_16</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 16 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_32">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_32</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 32 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_64">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_64</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 64 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_128">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_128</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 128 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_256">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_256</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 256 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_TRANS_RETIRED.LOAD_LATENCY_GT_512">MEM_TRANS_RETIRED.LOAD_LATENCY_GT_512</span></td>
		<td>Counts randomly selected loads when the latency from first dispatch to completion is greater than 512 cycles.  Reported latency may be longer than just the memory latency.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.STLB_MISS_LOADS">MEM_INST_RETIRED.STLB_MISS_LOADS</span></td>
		<td>Retired load instructions that miss the STLB.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.STLB_MISS_STORES">MEM_INST_RETIRED.STLB_MISS_STORES</span></td>
		<td>Retired store instructions that miss the STLB.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.LOCK_LOADS">MEM_INST_RETIRED.LOCK_LOADS</span></td>
		<td>Retired load instructions with locked access.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.SPLIT_LOADS">MEM_INST_RETIRED.SPLIT_LOADS</span></td>
		<td>Counts retired load instructions that split across a cacheline boundary.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.SPLIT_STORES">MEM_INST_RETIRED.SPLIT_STORES</span></td>
		<td>Counts retired store instructions that split across a cacheline boundary.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.ALL_LOADS">MEM_INST_RETIRED.ALL_LOADS</span></td>
		<td>All retired load instructions.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.ALL_STORES">MEM_INST_RETIRED.ALL_STORES</span></td>
		<td>All retired store instructions.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.STLB_MISS_LOADS_PS">MEM_INST_RETIRED.STLB_MISS_LOADS_PS</span></td>
		<td>Retired load instructions that miss the STLB.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.STLB_MISS_STORES_PS">MEM_INST_RETIRED.STLB_MISS_STORES_PS</span></td>
		<td>Retired store instructions that miss the STLB.</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.LOCK_LOADS_PS">MEM_INST_RETIRED.LOCK_LOADS_PS</span></td>
		<td>Retired load instructions with locked access. (Precise Event)</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.SPLIT_LOADS_PS">MEM_INST_RETIRED.SPLIT_LOADS_PS</span></td>
		<td>Retired load instructions that split across a cacheline boundary. (Precise Event)</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.SPLIT_STORES_PS">MEM_INST_RETIRED.SPLIT_STORES_PS</span></td>
		<td>Retired store instructions that split across a cacheline boundary. (Precise Event)</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.ALL_LOADS_PS">MEM_INST_RETIRED.ALL_LOADS_PS</span></td>
		<td>All retired load instructions. (Precise Event)</td>
	</tr>
	<tr>
		<td><span id="MEM_INST_RETIRED.ALL_STORES_PS">MEM_INST_RETIRED.ALL_STORES_PS</span></td>
		<td>All retired store instructions.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L1_HIT">MEM_LOAD_RETIRED.L1_HIT</span></td>
		<td>Counts retired load instructions with at least one uop that hit in the L1 data cache. This event includes all SW prefetches and lock instructions regardless of the data source.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L2_HIT">MEM_LOAD_RETIRED.L2_HIT</span></td>
		<td>Retired load instructions with L2 cache hits as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L3_HIT">MEM_LOAD_RETIRED.L3_HIT</span></td>
		<td>Counts retired load instructions with at least one uop that hit in the L3 cache. </td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L1_MISS">MEM_LOAD_RETIRED.L1_MISS</span></td>
		<td>Counts retired load instructions with at least one uop that missed in the L1 cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L2_MISS">MEM_LOAD_RETIRED.L2_MISS</span></td>
		<td>Retired load instructions missed L2 cache as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L3_MISS">MEM_LOAD_RETIRED.L3_MISS</span></td>
		<td>Counts retired load instructions with at least one uop that missed in the L3 cache. </td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.FB_HIT">MEM_LOAD_RETIRED.FB_HIT</span></td>
		<td>Counts retired load instructions with at least one uop was load missed in L1 but hit FB (Fill Buffers) due to preceding miss to the same cache line with data not ready. </td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L1_HIT_PS">MEM_LOAD_RETIRED.L1_HIT_PS</span></td>
		<td>Counts retired load instructions with at least one uop that hit in the L1 data cache. This event includes all SW prefetches and lock instructions regardless of the data source.
</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L2_HIT_PS">MEM_LOAD_RETIRED.L2_HIT_PS</span></td>
		<td>Retired load instructions with L2 cache hits as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L3_HIT_PS">MEM_LOAD_RETIRED.L3_HIT_PS</span></td>
		<td>Retired load instructions with L3 cache hits as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L1_MISS_PS">MEM_LOAD_RETIRED.L1_MISS_PS</span></td>
		<td>Counts retired load instructions with at least one uop that missed in the L1 cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L2_MISS_PS">MEM_LOAD_RETIRED.L2_MISS_PS</span></td>
		<td>Retired load instructions missed L2 cache as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.L3_MISS_PS">MEM_LOAD_RETIRED.L3_MISS_PS</span></td>
		<td>Retired load instructions missed L3 cache as data sources.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_RETIRED.FB_HIT_PS">MEM_LOAD_RETIRED.FB_HIT_PS</span></td>
		<td>Counts retired load instructions with at least one uop was load missed in L1 but hit FB (Fill Buffers) due to preceding miss to the same cache line with data not ready. 
</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_MISS">MEM_LOAD_L3_HIT_RETIRED.XSNP_MISS</span></td>
		<td>Retired load instructions which data sources were L3 hit and cross-core snoop missed in on-pkg core cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_HIT">MEM_LOAD_L3_HIT_RETIRED.XSNP_HIT</span></td>
		<td>Retired load instructions which data sources were L3 and cross-core snoop hits in on-pkg core cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_HITM">MEM_LOAD_L3_HIT_RETIRED.XSNP_HITM</span></td>
		<td>Retired load instructions which data sources were HitM responses from shared L3.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_NONE">MEM_LOAD_L3_HIT_RETIRED.XSNP_NONE</span></td>
		<td>Retired load instructions which data sources were hits in L3 without snoops required.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_MISS_PS">MEM_LOAD_L3_HIT_RETIRED.XSNP_MISS_PS</span></td>
		<td>Retired load instructions which data sources were L3 hit and cross-core snoop missed in on-pkg core cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_HIT_PS">MEM_LOAD_L3_HIT_RETIRED.XSNP_HIT_PS</span></td>
		<td>Retired load instructions which data sources were L3 and cross-core snoop hits in on-pkg core cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_HITM_PS">MEM_LOAD_L3_HIT_RETIRED.XSNP_HITM_PS</span></td>
		<td>Retired load instructions which data sources were HitM responses from shared L3.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_HIT_RETIRED.XSNP_NONE_PS">MEM_LOAD_L3_HIT_RETIRED.XSNP_NONE_PS</span></td>
		<td>Retired load instructions which data sources were hits in L3 without snoops required.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.LOCAL_DRAM">MEM_LOAD_L3_MISS_RETIRED.LOCAL_DRAM</span></td>
		<td>Retired load instructions which data sources missed L3 but serviced from local DRAM.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.LOCAL_DRAM_PS">MEM_LOAD_L3_MISS_RETIRED.LOCAL_DRAM_PS</span></td>
		<td>Retired load instructions which data sources missed L3 but serviced from local dram</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_FWD_PS">MEM_LOAD_L3_MISS_RETIRED.REMOTE_FWD_PS</span></td>
		<td>Retired load instructions whose data sources was forwarded from a remote cache</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_MISC_RETIRED.UC">MEM_LOAD_MISC_RETIRED.UC</span></td>
		<td>Retired instructions with at least 1 uncacheable load or lock.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_MISC_RETIRED.UC_PS">MEM_LOAD_MISC_RETIRED.UC_PS</span></td>
		<td>Retired instructions with at least 1 uncacheable load or lock.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.DSB_MISS">FRONTEND_RETIRED.DSB_MISS</span></td>
		<td>Counts retired Instructions that experienced DSB (Decode stream buffer i.e. the decoded instruction-cache) miss. </td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.L1I_MISS">FRONTEND_RETIRED.L1I_MISS</span></td>
		<td>Retired Instructions who experienced Instruction L1 Cache true miss.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.L2_MISS">FRONTEND_RETIRED.L2_MISS</span></td>
		<td>Retired Instructions who experienced Instruction L2 Cache true miss.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.ITLB_MISS">FRONTEND_RETIRED.ITLB_MISS</span></td>
		<td>Counts retired Instructions that experienced iTLB (Instruction TLB) true miss.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.STLB_MISS">FRONTEND_RETIRED.STLB_MISS</span></td>
		<td>Counts retired Instructions that experienced STLB (2nd level TLB) true miss. </td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2">FRONTEND_RETIRED.LATENCY_GE_2</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 2 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_2">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_2</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end had at least 2 bubble-slots for a period of 2 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_4">FRONTEND_RETIRED.LATENCY_GE_4</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 4 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.DSB_MISS_PS">FRONTEND_RETIRED.DSB_MISS_PS</span></td>
		<td>Counts retired Instructions that experienced DSB (Decode stream buffer i.e. the decoded instruction-cache) miss. 
</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.L1I_MISS_PS">FRONTEND_RETIRED.L1I_MISS_PS</span></td>
		<td>Retired Instructions who experienced Instruction L1 Cache true miss. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.L2_MISS_PS">FRONTEND_RETIRED.L2_MISS_PS</span></td>
		<td>Retired Instructions who experienced Instruction L2 Cache true miss. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.ITLB_MISS_PS">FRONTEND_RETIRED.ITLB_MISS_PS</span></td>
		<td>Counts retired Instructions that experienced iTLB (Instruction TLB) true miss.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.STLB_MISS_PS">FRONTEND_RETIRED.STLB_MISS_PS</span></td>
		<td>Counts retired Instructions that experienced STLB (2nd level TLB) true miss.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_PS">FRONTEND_RETIRED.LATENCY_GE_2_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 2 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_2_PS">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_2_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end had at least 2 bubble-slots for a period of 2 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_4_PS">FRONTEND_RETIRED.LATENCY_GE_4_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 4 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.THREAD">UOPS_EXECUTED.THREAD</span></td>
		<td>Number of uops to be executed per-thread each cycle.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE">UOPS_EXECUTED.CORE</span></td>
		<td>Number of uops executed from any thread.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.X87">UOPS_EXECUTED.X87</span></td>
		<td>Counts the number of x87 uops executed.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.STALL_CYCLES">UOPS_EXECUTED.STALL_CYCLES</span></td>
		<td>Counts cycles during which no uops were dispatched from the Reservation Station (RS) per thread.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC">UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC</span></td>
		<td>Cycles where at least 1 uop was executed per-thread.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CYCLES_GE_2_UOPS_EXEC">UOPS_EXECUTED.CYCLES_GE_2_UOPS_EXEC</span></td>
		<td>Cycles where at least 2 uops were executed per-thread.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CYCLES_GE_3_UOPS_EXEC">UOPS_EXECUTED.CYCLES_GE_3_UOPS_EXEC</span></td>
		<td>Cycles where at least 3 uops were executed per-thread.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CYCLES_GE_4_UOPS_EXEC">UOPS_EXECUTED.CYCLES_GE_4_UOPS_EXEC</span></td>
		<td>Cycles where at least 4 uops were executed per-thread.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.EXE_BOUND_0_PORTS">EXE_ACTIVITY.EXE_BOUND_0_PORTS</span></td>
		<td>Counts cycles during which no uops were executed on all ports and Reservation Station (RS) was not empty.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.1_PORTS_UTIL">EXE_ACTIVITY.1_PORTS_UTIL</span></td>
		<td>Counts cycles during which a total of 1 uop was executed on all ports and Reservation Station (RS) was not empty.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.2_PORTS_UTIL">EXE_ACTIVITY.2_PORTS_UTIL</span></td>
		<td>Counts cycles during which a total of 2 uops were executed on all ports and Reservation Station (RS) was not empty.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.3_PORTS_UTIL">EXE_ACTIVITY.3_PORTS_UTIL</span></td>
		<td>Cycles total of 3 uops are executed on all ports and Reservation Station (RS) was not empty.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.4_PORTS_UTIL">EXE_ACTIVITY.4_PORTS_UTIL</span></td>
		<td>Cycles total of 4 uops are executed on all ports and Reservation Station (RS) was not empty.</td>
	</tr>
	<tr>
		<td><span id="EXE_ACTIVITY.BOUND_ON_STORES">EXE_ACTIVITY.BOUND_ON_STORES</span></td>
		<td>Cycles where the Store Buffer was full and no outstanding load.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_0">UOPS_DISPATCHED_PORT.PORT_0</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 0.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_1">UOPS_DISPATCHED_PORT.PORT_1</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 1.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_2">UOPS_DISPATCHED_PORT.PORT_2</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 2.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_3">UOPS_DISPATCHED_PORT.PORT_3</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 3.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_4">UOPS_DISPATCHED_PORT.PORT_4</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 4.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_5">UOPS_DISPATCHED_PORT.PORT_5</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 5.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_6">UOPS_DISPATCHED_PORT.PORT_6</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 6.</td>
	</tr>
	<tr>
		<td><span id="UOPS_DISPATCHED_PORT.PORT_7">UOPS_DISPATCHED_PORT.PORT_7</span></td>
		<td>Counts, on the per-thread basis, cycles during which at least one uop is dispatched from the Reservation Station (RS) to port 7.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.STALLS_TOTAL">CYCLE_ACTIVITY.STALLS_TOTAL</span></td>
		<td>Total execution stalls.</td>
	</tr>
	<tr>
		<td><span id="EPT.WALK_PENDING">EPT.WALK_PENDING</span></td>
		<td>Counts cycles for each PMH (Page Miss Handler) that is busy with an EPT (Extended Page Table) walk for any request type.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.MISS_CAUSES_A_WALK">ITLB_MISSES.MISS_CAUSES_A_WALK</span></td>
		<td>Counts page walks of any page size (4K/2M/4M/1G) caused by a code fetch. This implies it missed in the ITLB and further levels of TLB, but the walk need not have completed.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_COMPLETED_4K">ITLB_MISSES.WALK_COMPLETED_4K</span></td>
		<td>Counts completed page walks (4K page size) caused by a code fetch. This implies it missed in the ITLB and further levels of TLB. The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_COMPLETED_2M_4M">ITLB_MISSES.WALK_COMPLETED_2M_4M</span></td>
		<td>Counts code misses in all ITLB levels that caused a completed page walk (2M and 4M page sizes). The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_COMPLETED_1G">ITLB_MISSES.WALK_COMPLETED_1G</span></td>
		<td>Counts store misses in all DTLB levels that cause a completed page walk (1G page size). The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_PENDING">ITLB_MISSES.WALK_PENDING</span></td>
		<td>Counts 1 per cycle for each PMH (Page Miss Handler) that is busy with a page walk for an instruction fetch request. EPT page walk duration are excluded in Skylake michroarchitecture. </td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.STLB_HIT">ITLB_MISSES.STLB_HIT</span></td>
		<td>Instruction fetch requests that miss the ITLB and hit the STLB.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.MISS_CAUSES_A_WALK">DTLB_LOAD_MISSES.MISS_CAUSES_A_WALK</span></td>
		<td>Counts demand data loads that caused a page walk of any page size (4K/2M/4M/1G). This implies it missed in all TLB levels, but the walk need not have completed.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_COMPLETED_4K">DTLB_LOAD_MISSES.WALK_COMPLETED_4K</span></td>
		<td>Counts page walks completed due to demand data loads whose address translations missed in the TLB and were mapped to 4K pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_COMPLETED_2M_4M">DTLB_LOAD_MISSES.WALK_COMPLETED_2M_4M</span></td>
		<td>Counts page walks completed due to demand data loads whose address translations missed in the TLB and were mapped to 2M/4M pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_COMPLETED_1G">DTLB_LOAD_MISSES.WALK_COMPLETED_1G</span></td>
		<td>Counts page walks completed due to demand data loads whose address translations missed in the TLB and were mapped to 4K pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_PENDING">DTLB_LOAD_MISSES.WALK_PENDING</span></td>
		<td>Counts 1 per cycle for each PMH that is busy with a page walk for a load. EPT page walk duration are excluded in Skylake microarchitecture. </td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.STLB_HIT">DTLB_LOAD_MISSES.STLB_HIT</span></td>
		<td>Counts loads that miss the DTLB (Data TLB) and hit the STLB (Second level TLB).</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.MISS_CAUSES_A_WALK">DTLB_STORE_MISSES.MISS_CAUSES_A_WALK</span></td>
		<td>Counts demand data stores that caused a page walk of any page size (4K/2M/4M/1G). This implies it missed in all TLB levels, but the walk need not have completed.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_COMPLETED_4K">DTLB_STORE_MISSES.WALK_COMPLETED_4K</span></td>
		<td>Counts page walks completed due to demand data stores whose address translations missed in the TLB and were mapped to 4K pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_COMPLETED_2M_4M">DTLB_STORE_MISSES.WALK_COMPLETED_2M_4M</span></td>
		<td>Counts page walks completed due to demand data stores whose address translations missed in the TLB and were mapped to 2M/4M pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_COMPLETED_1G">DTLB_STORE_MISSES.WALK_COMPLETED_1G</span></td>
		<td>Counts page walks completed due to demand data stores whose address translations missed in the TLB and were mapped to 1G pages.  The page walks can end with or without a page fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_PENDING">DTLB_STORE_MISSES.WALK_PENDING</span></td>
		<td>Counts 1 per cycle for each PMH that is busy with a page walk for a store. EPT page walk duration are excluded in Skylake microarchitecture. </td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.STLB_HIT">DTLB_STORE_MISSES.STLB_HIT</span></td>
		<td>Stores that miss the DTLB (Data TLB) and hit the STLB (2nd Level TLB).</td>
	</tr>
	<tr>
		<td><span id="TLB_FLUSH.DTLB_THREAD">TLB_FLUSH.DTLB_THREAD</span></td>
		<td>Counts the number of DTLB flush attempts of the thread-specific entries.</td>
	</tr>
	<tr>
		<td><span id="TLB_FLUSH.STLB_ANY">TLB_FLUSH.STLB_ANY</span></td>
		<td>Counts the number of any STLB flush attempts (such as entire, VPID, PCID, InvPage, CR3 write, etc.).</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.CYCLES_L1D_MISS">CYCLE_ACTIVITY.CYCLES_L1D_MISS</span></td>
		<td>Cycles while L1 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.STALLS_L1D_MISS">CYCLE_ACTIVITY.STALLS_L1D_MISS</span></td>
		<td>Execution stalls while L1 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="L1D.REPLACEMENT">L1D.REPLACEMENT</span></td>
		<td>Counts L1D data line replacements including opportunistic replacements, and replacements that require stall-for-replace or block-for-replace.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_CONFLICT">TX_MEM.ABORT_CONFLICT</span></td>
		<td>Number of times a TSX line had a cache conflict.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_CAPACITY">TX_MEM.ABORT_CAPACITY</span></td>
		<td>Number of times a transactional abort was signaled due to a data capacity limitation for transactional reads or writes.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_HLE_STORE_TO_ELIDED_LOCK">TX_MEM.ABORT_HLE_STORE_TO_ELIDED_LOCK</span></td>
		<td>Number of times a TSX Abort was triggered due to a non-release/commit store to lock.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_HLE_ELISION_BUFFER_NOT_EMPTY">TX_MEM.ABORT_HLE_ELISION_BUFFER_NOT_EMPTY</span></td>
		<td>Number of times a TSX Abort was triggered due to commit but Lock Buffer not empty.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_HLE_ELISION_BUFFER_MISMATCH">TX_MEM.ABORT_HLE_ELISION_BUFFER_MISMATCH</span></td>
		<td>Number of times a TSX Abort was triggered due to release/commit but data and address mismatch.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.ABORT_HLE_ELISION_BUFFER_UNSUPPORTED_ALIGNMENT">TX_MEM.ABORT_HLE_ELISION_BUFFER_UNSUPPORTED_ALIGNMENT</span></td>
		<td>Number of times a TSX Abort was triggered due to attempting an unsupported alignment from Lock Buffer.</td>
	</tr>
	<tr>
		<td><span id="TX_MEM.HLE_ELISION_BUFFER_FULL">TX_MEM.HLE_ELISION_BUFFER_FULL</span></td>
		<td>Number of times we could not allocate Lock Buffer.</td>
	</tr>
	<tr>
		<td><span id="L1D_PEND_MISS.PENDING">L1D_PEND_MISS.PENDING</span></td>
		<td>Counts duration of L1D miss outstanding, that is each cycle number of Fill Buffers (FB) outstanding required by Demand Reads. FB either is held by demand loads, or it is held by non-demand loads and gets hit at least once by demand. The valid outstanding interval is defined until the FB deallocation by one of the following ways: from FB allocation, if FB is allocated by demand from the demand Hit FB, if it is allocated by hardware or software prefetch.Note: In the L1D, a Demand Read contains cacheable or noncacheable demand loads, including ones causing cache-line splits and reads due to page walks resulted from any request type.</td>
	</tr>
	<tr>
		<td><span id="L1D_PEND_MISS.FB_FULL">L1D_PEND_MISS.FB_FULL</span></td>
		<td>Number of times a request needed a FB (Fill Buffer) entry but there was no entry available for it. A request includes cacheable/uncacheable demands that are load, store or SW prefetch instructions.</td>
	</tr>
	<tr>
		<td><span id="L1D_PEND_MISS.PENDING_CYCLES">L1D_PEND_MISS.PENDING_CYCLES</span></td>
		<td>Counts duration of L1D miss outstanding in cycles.</td>
	</tr>
	<tr>
		<td><span id="SW_PREFETCH_ACCESS.NTA">SW_PREFETCH_ACCESS.NTA</span></td>
		<td>Number of PREFETCHNTA instructions executed.</td>
	</tr>
	<tr>
		<td><span id="SW_PREFETCH_ACCESS.T0">SW_PREFETCH_ACCESS.T0</span></td>
		<td>Number of PREFETCHT0 instructions executed.</td>
	</tr>
	<tr>
		<td><span id="SW_PREFETCH_ACCESS.T1_T2">SW_PREFETCH_ACCESS.T1_T2</span></td>
		<td>Number of PREFETCHT1 or PREFETCHT2 instructions executed.</td>
	</tr>
	<tr>
		<td><span id="SW_PREFETCH_ACCESS.PREFETCHW">SW_PREFETCH_ACCESS.PREFETCHW</span></td>
		<td>Number of PREFETCHW instructions executed.</td>
	</tr>
	<tr>
		<td><span id="LOAD_HIT_PRE.SW_PF">LOAD_HIT_PRE.SW_PF</span></td>
		<td>Counts all not software-prefetch load dispatches that hit the fill buffer (FB) allocated for the software prefetch. It can also be incremented by some lock instructions. So it should only be used with profiling so that the locks can be excluded by ASM (Assembly File) inspection of the nearby instructions.</td>
	</tr>
	<tr>
		<td><span id="MEMORY_DISAMBIGUATION.HISTORY_RESET">MEMORY_DISAMBIGUATION.HISTORY_RESET</span></td>
		<td>tbd</td>
	</tr>
	<tr>
		<td><span id="LD_BLOCKS.STORE_FORWARD">LD_BLOCKS.STORE_FORWARD</span></td>
		<td>Counts the number of times where store forwarding was prevented for a load operation. The most common case is a load blocked due to the address of memory access (partially) overlapping with a preceding uncompleted store. Note: See the table of not supported store forwards in the Optimization Guide.</td>
	</tr>
	<tr>
		<td><span id="LD_BLOCKS.NO_SR">LD_BLOCKS.NO_SR</span></td>
		<td>The number of times that split load operations are temporarily blocked because all resources for handling the split accesses are in use.</td>
	</tr>
	<tr>
		<td><span id="LD_BLOCKS_PARTIAL.ADDRESS_ALIAS">LD_BLOCKS_PARTIAL.ADDRESS_ALIAS</span></td>
		<td>Counts false dependencies in MOB when the partial comparison upon loose net check and dependency was resolved by the Enhanced Loose net mechanism. This may not result in high performance penalties. Loose net checks can fail when loads and stores are 4k aliased.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.DEMAND_DATA_RD">OFFCORE_REQUESTS.DEMAND_DATA_RD</span></td>
		<td>Counts the Demand Data Read requests sent to uncore. Use it in conjunction with OFFCORE_REQUESTS_OUTSTANDING to determine average latency in the uncore.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.DEMAND_CODE_RD">OFFCORE_REQUESTS.DEMAND_CODE_RD</span></td>
		<td>Counts both cacheable and non-cacheable code read requests.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.DEMAND_RFO">OFFCORE_REQUESTS.DEMAND_RFO</span></td>
		<td>Counts the demand RFO (read for ownership) requests including regular RFOs, locks, ItoM.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.ALL_DATA_RD">OFFCORE_REQUESTS.ALL_DATA_RD</span></td>
		<td>Counts the demand and prefetch data reads. All Core Data Reads include cacheable &#39;Demands&#39; and L2 prefetchers (not L3 prefetchers). Counting also covers reads due to page walks resulted from any request type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.L3_MISS_DEMAND_DATA_RD">OFFCORE_REQUESTS.L3_MISS_DEMAND_DATA_RD</span></td>
		<td>Demand Data Read requests who miss L3 cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS.ALL_REQUESTS">OFFCORE_REQUESTS.ALL_REQUESTS</span></td>
		<td>Counts memory transactions reached the super queue including requests initiated by the core, all L3 prefetches, page walks, etc..</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD</span></td>
		<td>Counts the number of offcore outstanding Demand Data Read transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor. See the corresponding Umask under OFFCORE_REQUESTS.Note: A prefetch promoted to Demand is counted from the promotion point.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.DEMAND_CODE_RD">OFFCORE_REQUESTS_OUTSTANDING.DEMAND_CODE_RD</span></td>
		<td>Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The &#39;Offcore outstanding&#39; state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.DEMAND_RFO">OFFCORE_REQUESTS_OUTSTANDING.DEMAND_RFO</span></td>
		<td>Counts the number of offcore outstanding RFO (store) transactions in the super queue (SQ) every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.ALL_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.ALL_DATA_RD</span></td>
		<td>Counts the number of offcore outstanding cacheable Core Data Read transactions in the super queue every cycle. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.L3_MISS_DEMAND_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.L3_MISS_DEMAND_DATA_RD</span></td>
		<td>Counts number of Offcore outstanding Demand Data Read requests that miss L3 cache in the superQ every cycle.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_DATA_RD</span></td>
		<td>Counts cycles when offcore outstanding Demand Data Read transactions are present in the super queue (SQ). A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation).</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DATA_RD</span></td>
		<td>Counts cycles when offcore outstanding cacheable Core Data Read transactions are present in the super queue. A transaction is considered to be in the Offcore outstanding state between L2 miss and transaction completion sent to requestor (SQ de-allocation). See corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_BUFFER.SQ_FULL">OFFCORE_REQUESTS_BUFFER.SQ_FULL</span></td>
		<td>Counts the number of cases when the offcore requests buffer cannot take more entries for the core. This can happen when the superqueue does not contain eligible entries, or when L1D writeback pending FIFO requests is full.Note: Writeback pending FIFO has six entries.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.CYCLES_L2_MISS">CYCLE_ACTIVITY.CYCLES_L2_MISS</span></td>
		<td>Cycles while L2 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.STALLS_L2_MISS">CYCLE_ACTIVITY.STALLS_L2_MISS</span></td>
		<td>Execution stalls while L2 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.CYCLES_MEM_ANY">CYCLE_ACTIVITY.CYCLES_MEM_ANY</span></td>
		<td>Cycles while memory subsystem has an outstanding load.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.STALLS_MEM_ANY">CYCLE_ACTIVITY.STALLS_MEM_ANY</span></td>
		<td>Execution stalls while memory subsystem has an outstanding load.</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_IHITI">CORE_SNOOP_RESPONSE.RSP_IHITI</span></td>
		<td>RspIHitI IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_IHITFSE">CORE_SNOOP_RESPONSE.RSP_IHITFSE</span></td>
		<td>RspIHitFSE IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_SHITFSE">CORE_SNOOP_RESPONSE.RSP_SHITFSE</span></td>
		<td>RspSHitFSE IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_SFWDM">CORE_SNOOP_RESPONSE.RSP_SFWDM</span></td>
		<td>RspSFwdM IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_IFWDM">CORE_SNOOP_RESPONSE.RSP_IFWDM</span></td>
		<td>RspIFwdM IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_IFWDFE">CORE_SNOOP_RESPONSE.RSP_IFWDFE</span></td>
		<td>RspIFwdFE IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="CORE_SNOOP_RESPONSE.RSP_SFWDFE">CORE_SNOOP_RESPONSE.RSP_SFWDFE</span></td>
		<td>RspSFwdFE IDI response was returned to Uncore</td>
	</tr>
	<tr>
		<td><span id="L2_TRANS.L2_WB">L2_TRANS.L2_WB</span></td>
		<td>Counts L2 writebacks that access L2 cache.</td>
	</tr>
	<tr>
		<td><span id="LONGEST_LAT_CACHE.MISS">LONGEST_LAT_CACHE.MISS</span></td>
		<td>Counts core-originated cacheable requests that miss the L3 cache (Longest Latency cache). Requests include data and code reads, Reads-for-Ownership (RFOs), speculative accesses and hardware prefetches from L1 and L2. It does not include all misses to the L3.
</td>
	</tr>
	<tr>
		<td><span id="LONGEST_LAT_CACHE.REFERENCE">LONGEST_LAT_CACHE.REFERENCE</span></td>
		<td>Counts core-originated cacheable requests to the  L3 cache (Longest Latency cache). Requests include data and code reads, Reads-for-Ownership (RFOs), speculative accesses and hardware prefetches from L1 and L2.  It does not include all accesses to the L3.
</td>
	</tr>
	<tr>
		<td><span id="SQ_MISC.SPLIT_LOCK">SQ_MISC.SPLIT_LOCK</span></td>
		<td>Counts the number of cache line split locks sent to the uncore.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.REF_XCLK">CPU_CLK_THREAD_UNHALTED.REF_XCLK</span></td>
		<td>Core crystal clock cycles when the thread is unhalted.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_THREAD_UNHALTED.ONE_THREAD_ACTIVE">CPU_CLK_THREAD_UNHALTED.ONE_THREAD_ACTIVE</span></td>
		<td>Core crystal clock cycles when this thread is unhalted and the other thread is halted.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.DEMAND_DATA_RD_MISS">L2_RQSTS.DEMAND_DATA_RD_MISS</span></td>
		<td>Counts the number of demand Data Read requests that miss L2 cache. Only not rejected loads are counted.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.DEMAND_DATA_RD_HIT">L2_RQSTS.DEMAND_DATA_RD_HIT</span></td>
		<td>Counts the number of demand Data Read requests, initiated by load instructions, that hit L2 cache</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_DEMAND_DATA_RD">L2_RQSTS.ALL_DEMAND_DATA_RD</span></td>
		<td>Counts the number of demand Data Read requests (including requests from L1D hardware prefetchers). These loads may hit or miss L2 cache. Only non rejected loads are counted.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_RFO">L2_RQSTS.ALL_RFO</span></td>
		<td>Counts the total number of RFO (read for ownership) requests to L2 cache. L2 RFO requests include both L1D demand RFO misses as well as L1D RFO prefetches.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_CODE_RD">L2_RQSTS.ALL_CODE_RD</span></td>
		<td>Counts the total number of L2 code requests.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_PF">L2_RQSTS.ALL_PF</span></td>
		<td>Counts the total number of requests from the L2 hardware prefetchers.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.PF_MISS">L2_RQSTS.PF_MISS</span></td>
		<td>Counts requests from the L1/L2/L3 hardware prefetchers or Load software prefetches that miss L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.PF_HIT">L2_RQSTS.PF_HIT</span></td>
		<td>Counts requests from the L1/L2/L3 hardware prefetchers or Load software prefetches that hit L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.RFO_HIT">L2_RQSTS.RFO_HIT</span></td>
		<td>Counts the RFO (Read-for-Ownership) requests that hit L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.RFO_MISS">L2_RQSTS.RFO_MISS</span></td>
		<td>Counts the RFO (Read-for-Ownership) requests that miss L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.CODE_RD_HIT">L2_RQSTS.CODE_RD_HIT</span></td>
		<td>Counts L2 cache hits when fetching instructions, code reads.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.CODE_RD_MISS">L2_RQSTS.CODE_RD_MISS</span></td>
		<td>Counts L2 cache misses when fetching instructions.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_DEMAND_MISS">L2_RQSTS.ALL_DEMAND_MISS</span></td>
		<td>Demand requests that miss L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.ALL_DEMAND_REFERENCES">L2_RQSTS.ALL_DEMAND_REFERENCES</span></td>
		<td>Demand requests to L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.MISS">L2_RQSTS.MISS</span></td>
		<td>All requests that miss L2 cache.</td>
	</tr>
	<tr>
		<td><span id="L2_RQSTS.REFERENCES">L2_RQSTS.REFERENCES</span></td>
		<td>All L2 requests.</td>
	</tr>
	<tr>
		<td><span id="L2_LINES_OUT.SILENT">L2_LINES_OUT.SILENT</span></td>
		<td>Counts the number of lines that are silently dropped by L2 cache when triggered by an L2 cache fill. These lines are typically in Shared state. A non-threaded event.</td>
	</tr>
	<tr>
		<td><span id="L2_LINES_OUT.NON_SILENT">L2_LINES_OUT.NON_SILENT</span></td>
		<td>Counts the number of lines that are evicted by L2 cache when triggered by an L2 cache fill. Those lines can be either in modified state or clean state. Modified lines may either be written back to L3 or directly written to memory and not allocated in L3.  Clean lines may either be allocated in L3 or dropped.</td>
	</tr>
	<tr>
		<td><span id="L2_LINES_OUT.USELESS_HWPF">L2_LINES_OUT.USELESS_PREF</span></td>
		<td>This event is deprecated. Refer to new event L2_LINES_OUT.USELESS_HWPF</td>
	</tr>
	<tr>
		<td><span id="IDQ.MS_SWITCHES">IDQ.MS_SWITCHES</span></td>
		<td>Number of switches from DSB (Decode Stream Buffer) or MITE (legacy decode pipeline) to the Microcode Sequencer.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_COMPLETED">ITLB_MISSES.WALK_COMPLETED</span></td>
		<td>Counts completed page walks (2M and 4M page sizes) caused by a code fetch. This implies it missed in the ITLB and further levels of TLB. The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_COMPLETED">DTLB_LOAD_MISSES.WALK_COMPLETED</span></td>
		<td>Counts demand data loads that caused a completed page walk of any page size (4K/2M/4M/1G). This implies it missed in all TLB levels. The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_COMPLETED">DTLB_STORE_MISSES.WALK_COMPLETED</span></td>
		<td>Counts demand data stores that caused a completed page walk of any page size (4K/2M/4M/1G). This implies it missed in all TLB levels. The page walk can end with or without a fault.</td>
	</tr>
	<tr>
		<td><span id="IDQ.MS_UOPS">IDQ.MS_UOPS</span></td>
		<td>Counts the total number of uops delivered by the Microcode Sequencer (MS). Any instruction over 4 uops will be delivered by the MS. Some instructions such as transcendentals may additionally generate uops from the MS.</td>
	</tr>
	<tr>
		<td><span id="L2_LINES_IN.ALL">L2_LINES_IN.ALL</span></td>
		<td>Counts the number of L2 cache lines filling the L2. Counting does not cover rejects.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_CODE_RD">OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_CODE_RD</span></td>
		<td>Counts the number of offcore outstanding Code Reads transactions in the super queue every cycle. The &#39;Offcore outstanding&#39; state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_RFO">OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_RFO</span></td>
		<td>Counts the number of offcore outstanding demand rfo Reads transactions in the super queue every cycle. The &#39;Offcore outstanding&#39; state of the transaction lasts from the L2 miss until the sending transaction completion to requestor (SQ deallocation). See the corresponding Umask under OFFCORE_REQUESTS.</td>
	</tr>
	<tr>
		<td><span id="INST_RETIRED.TOTAL_CYCLES_PS">INST_RETIRED.TOTAL_CYCLES_PS</span></td>
		<td>Number of cycles using an always true condition applied to  PEBS instructions retired event. (inst_ret&lt; 16)</td>
	</tr>
	<tr>
		<td><span id="ARITH.DIVIDER_ACTIVE">ARITH.DIVIDER_ACTIVE</span></td>
		<td>Cycles when divide unit is busy executing divide or square root operations. Accounts for integer and floating-point operations.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.CYCLES_L3_MISS">CYCLE_ACTIVITY.CYCLES_L3_MISS</span></td>
		<td>Cycles while L3 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="CYCLE_ACTIVITY.STALLS_L3_MISS">CYCLE_ACTIVITY.STALLS_L3_MISS</span></td>
		<td>Execution stalls while L3 cache miss demand load is outstanding.</td>
	</tr>
	<tr>
		<td><span id="LSD.CYCLES_ACTIVE">LSD.CYCLES_ACTIVE</span></td>
		<td>Counts the cycles when at least one uop is delivered by the LSD (Loop-stream detector).</td>
	</tr>
	<tr>
		<td><span id="LSD.CYCLES_4_UOPS">LSD.CYCLES_4_UOPS</span></td>
		<td>Counts the cycles when 4 uops are delivered by the LSD (Loop-stream detector).</td>
	</tr>
	<tr>
		<td><span id="OTHER_ASSISTS.ANY">OTHER_ASSISTS.ANY</span></td>
		<td>Number of times a microcode assist is invoked by HW other than FP-assist. Examples include AD (page Access Dirty) and AVX* related assists.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_L3_MISS_DEMAND_DATA_RD">OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_L3_MISS_DEMAND_DATA_RD</span></td>
		<td>Cycles with at least 1 Demand Data Read requests who miss L3 cache in the superQ.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.L3_MISS_DEMAND_DATA_RD_GE_6">OFFCORE_REQUESTS_OUTSTANDING.L3_MISS_DEMAND_DATA_RD_GE_6</span></td>
		<td>Cycles with at least 6 Demand Data Read requests that miss L3 cache in the superQ.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_8">FRONTEND_RETIRED.LATENCY_GE_8</span></td>
		<td>Counts retired instructions that are delivered to the back-end after a front-end stall of at least 8 cycles. During this period the front-end delivered no uops.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_16">FRONTEND_RETIRED.LATENCY_GE_16</span></td>
		<td>Counts retired instructions that are delivered to the back-end after a front-end stall of at least 16 cycles. During this period the front-end delivered no uops.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_32">FRONTEND_RETIRED.LATENCY_GE_32</span></td>
		<td>Counts retired instructions that are delivered to the back-end after a front-end stall of at least 32 cycles. During this period the front-end delivered no uops.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_64">FRONTEND_RETIRED.LATENCY_GE_64</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 64 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_128">FRONTEND_RETIRED.LATENCY_GE_128</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 128 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_256">FRONTEND_RETIRED.LATENCY_GE_256</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 256 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_512">FRONTEND_RETIRED.LATENCY_GE_512</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 512 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_1">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_1</span></td>
		<td>Counts retired instructions that are delivered to the back-end after the front-end had at least 1 bubble-slot for a period of 2 cycles. A bubble-slot is an empty issue-pipeline slot while there was no RAT stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_1_PS">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_1_PS</span></td>
		<td>Counts retired instructions that are delivered to the back-end after the front-end had at least 1 bubble-slot for a period of 2 cycles. A bubble-slot is an empty issue-pipeline slot while there was no RAT stall.
</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_3">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_3</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end had at least 3 bubble-slots for a period of 2 cycles which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_8_PS">FRONTEND_RETIRED.LATENCY_GE_8_PS</span></td>
		<td>Counts retired instructions that are delivered to the back-end after a front-end stall of at least 8 cycles. During this period the front-end delivered no uops. 
</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_16_PS">FRONTEND_RETIRED.LATENCY_GE_16_PS</span></td>
		<td>Counts retired instructions that are delivered to the back-end after a front-end stall of at least 16 cycles. During this period the front-end delivered no uops.
</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_32_PS">FRONTEND_RETIRED.LATENCY_GE_32_PS</span></td>
		<td>Counts retired instructions that are delivered to the back-end  after a front-end stall of at least 32 cycles. During this period the front-end delivered no uops.
</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_64_PS">FRONTEND_RETIRED.LATENCY_GE_64_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 64 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_128_PS">FRONTEND_RETIRED.LATENCY_GE_128_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 128 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_256_PS">FRONTEND_RETIRED.LATENCY_GE_256_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 256 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_512_PS">FRONTEND_RETIRED.LATENCY_GE_512_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of 512 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_3_PS">FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_3_PS</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end had at least 3 bubble-slots for a period of 2 cycles which was not interrupted by a back-end stall. Precise Event.</td>
	</tr>
	<tr>
		<td><span id="DTLB_STORE_MISSES.WALK_ACTIVE">DTLB_STORE_MISSES.WALK_ACTIVE</span></td>
		<td>Counts cycles when at least one PMH (Page Miss Handler) is busy with a page walk for a store.</td>
	</tr>
	<tr>
		<td><span id="DTLB_LOAD_MISSES.WALK_ACTIVE">DTLB_LOAD_MISSES.WALK_ACTIVE</span></td>
		<td>Counts cycles when at least one PMH (Page Miss Handler) is busy with a page walk for a load.</td>
	</tr>
	<tr>
		<td><span id="ITLB_MISSES.WALK_ACTIVE">ITLB_MISSES.WALK_ACTIVE</span></td>
		<td>Cycles when at least one PMH is busy with a page walk for code (instruction fetch) request. EPT page walk duration are excluded in Skylake microarchitecture.</td>
	</tr>
	<tr>
		<td><span id="UOPS_ISSUED.VECTOR_WIDTH_MISMATCH">UOPS_ISSUED.VECTOR_WIDTH_MISMATCH</span></td>
		<td>Counts the number of Blend Uops issued by the Resource Allocation Table (RAT) to the reservation station (RS) in order to preserve upper bits of vector registers. Starting with the Skylake microarchitecture, these Blend uops are needed since every Intel SSE instruction executed in Dirty Upper State needs to preserve bits 128-255 of the destination register. For more information, refer to “Mixing Intel AVX and Intel SSE Code” section of the Optimization Guide.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.THREAD_ANY">CPU_CLK_UNHALTED.THREAD_ANY</span></td>
		<td>Core cycles when at least one thread on the physical core is not in halt state.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.THREAD_P_ANY">CPU_CLK_UNHALTED.THREAD_P_ANY</span></td>
		<td>Core cycles when at least one thread on the physical core is not in halt state.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.REF_XCLK_ANY">CPU_CLK_THREAD_UNHALTED.REF_XCLK_ANY</span></td>
		<td>Core crystal clock cycles when at least one thread on the physical core is unhalted.</td>
	</tr>
	<tr>
		<td><span id="INT_MISC.RECOVERY_CYCLES_ANY">INT_MISC.RECOVERY_CYCLES_ANY</span></td>
		<td>Core cycles the allocator was stalled due to recovery from earlier clear event for any thread running on the physical core (e.g. misprediction or memory nuke).</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE_CYCLES_GE_1">UOPS_EXECUTED.CORE_CYCLES_GE_1</span></td>
		<td>Cycles at least 1 micro-op is executed from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE_CYCLES_GE_2">UOPS_EXECUTED.CORE_CYCLES_GE_2</span></td>
		<td>Cycles at least 2 micro-op is executed from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE_CYCLES_GE_3">UOPS_EXECUTED.CORE_CYCLES_GE_3</span></td>
		<td>Cycles at least 3 micro-op is executed from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE_CYCLES_GE_4">UOPS_EXECUTED.CORE_CYCLES_GE_4</span></td>
		<td>Cycles at least 4 micro-op is executed from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="UOPS_EXECUTED.CORE_CYCLES_NONE">UOPS_EXECUTED.CORE_CYCLES_NONE</span></td>
		<td>Cycles with no micro-ops executed from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="L1D_PEND_MISS.PENDING_CYCLES_ANY">L1D_PEND_MISS.PENDING_CYCLES_ANY</span></td>
		<td>Cycles with L1D load Misses outstanding from any thread on physical core.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD_GE_6">OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD_GE_6</span></td>
		<td>Cycles with at least 6 offcore outstanding Demand Data Read transactions in uncore queue.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.RING0_TRANS">CPU_CLK_UNHALTED.RING0_TRANS</span></td>
		<td>Counts when the Current Privilege Level (CPL) transitions from ring 1, 2 or 3 to ring 0 (Kernel).</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_THREAD_UNHALTED.REF_XCLK">CPU_CLK_UNHALTED.REF_XCLK</span></td>
		<td>Core crystal clock cycles when the thread is unhalted.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_THREAD_UNHALTED.REF_XCLK_ANY">CPU_CLK_UNHALTED.REF_XCLK_ANY</span></td>
		<td>Core crystal clock cycles when at least one thread on the physical core is unhalted.</td>
	</tr>
	<tr>
		<td><span id="CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE">CPU_CLK_UNHALTED.ONE_THREAD_ACTIVE</span></td>
		<td>Core crystal clock cycles when this thread is unhalted and the other thread is halted.</td>
	</tr>
	<tr>
		<td><span id="L2_LINES_OUT.USELESS_PREF">L2_LINES_OUT.USELESS_HWPF</span></td>
		<td>Counts the number of lines that have been hardware prefetched but not used and now evicted by L2 cache</td>
	</tr>
	<tr>
		<td><span id="ROB_MISC_EVENTS.PAUSE_INST">ROB_MISC_EVENTS.PAUSE_INST</span></td>
		<td>Number of retired PAUSE instructions (that do not end up with a VMExit to the VMM; TSX aborted Instructions may be counted). This event is not supported on first SKL and KBL products.</td>
	</tr>
	<tr>
		<td><span id="BR_INST_RETIRED.COND_NTAKEN">BR_INST_RETIRED.COND_NTAKEN</span></td>
		<td>This event counts not taken branch instructions retired.</td>
	</tr>
	<tr>
		<td><span id="FRONTEND_RETIRED.LATENCY_GE_1">FRONTEND_RETIRED.LATENCY_GE_1</span></td>
		<td>Retired instructions that are fetched after an interval where the front-end delivered no uops for a period of at least 1 cycle which was not interrupted by a back-end stall.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.512B_PACKED_DOUBLE">FP_ARITH_INST_RETIRED.512B_PACKED_DOUBLE</span></td>
		<td>Number of SSE/AVX computational 512-bit packed double precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 8 computation operations, one for each element.  Applies to SSE* and AVX* packed double precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 8 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="FP_ARITH_INST_RETIRED.512B_PACKED_SINGLE">FP_ARITH_INST_RETIRED.512B_PACKED_SINGLE</span></td>
		<td>Number of SSE/AVX computational 512-bit packed single precision floating-point instructions retired; some instructions will count twice as noted below.  Each count represents 16 computation operations, one for each element.  Applies to SSE* and AVX* packed single precision floating-point instructions: ADD SUB MUL DIV MIN MAX RCP14 RSQRT14 SQRT DPP FM(N)ADD/SUB.  DPP and FM(N)ADD/SUB instructions count twice as they perform 16 calculations per element.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_DRAM">MEM_LOAD_L3_MISS_RETIRED.REMOTE_DRAM</span></td>
		<td>Retired load instructions which data sources missed L3 but serviced from remote dram</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_HITM">MEM_LOAD_L3_MISS_RETIRED.REMOTE_HITM</span></td>
		<td>Retired load instructions whose data sources was remote HITM.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_FWD">MEM_LOAD_L3_MISS_RETIRED.REMOTE_FWD</span></td>
		<td>Retired load instructions whose data sources was forwarded from a remote cache.</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_DRAM_PS">MEM_LOAD_L3_MISS_RETIRED.REMOTE_DRAM_PS</span></td>
		<td>Retired load instructions which data sources missed L3 but serviced from remote dram</td>
	</tr>
	<tr>
		<td><span id="MEM_LOAD_L3_MISS_RETIRED.REMOTE_HITM_PS">MEM_LOAD_L3_MISS_RETIRED.REMOTE_HITM_PS</span></td>
		<td>Retired load instructions whose data sources was remote HITM</td>
	</tr>
	<tr>
		<td><span id="IDI_MISC.WB_UPGRADE">IDI_MISC.WB_UPGRADE</span></td>
		<td>Counts number of cache lines that are allocated and written back to L3 with the intention that they are more likely to be reused shortly.</td>
	</tr>
	<tr>
		<td><span id="IDI_MISC.WB_DOWNGRADE">IDI_MISC.WB_DOWNGRADE</span></td>
		<td>Counts number of cache lines that are dropped and not written back to L3 as they are deemed to be less likely to be reused shortly.</td>
	</tr>
	<tr>
		<td><span id="CORE_POWER.THROTTLE">CORE_POWER.THROTTLE</span></td>
		<td>Core cycles the out-of-order engine was throttled due to a pending power level request.</td>
	</tr>
	<tr>
		<td><span id="CORE_POWER.LEVEL_BASELINE">CORE_POWER.LVL0_TURBO_LICENSE</span></td>
		<td>Core cycles where the core was running with power-delivery for baseline license level 0.  This includes non-AVX codes, SSE, AVX 128-bit, and low-current AVX 256-bit codes.</td>
	</tr>
	<tr>
		<td><span id="CORE_POWER.LEVEL_AVX256">CORE_POWER.LVL1_TURBO_LICENSE</span></td>
		<td>Core cycles where the core was running with power-delivery for license level 1.  This includes high current AVX 256-bit instructions as well as low current AVX 512-bit instructions.</td>
	</tr>
	<tr>
		<td><span id="CORE_POWER.LEVEL_AVX512">CORE_POWER.LVL2_TURBO_LICENSE</span></td>
		<td>Core cycles where the core was running with power-delivery for license level 2 (introduced in Skylake Server michroarchtecture).  This includes high current AVX 512-bit instructions.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_CLOCKTICKS">UNC_C_CLOCKTICKS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_CLOCKTICKS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_CORE_SNP.CORE_GTONE">UNC_H_CORE_SNP.CORE_GTONE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_CORE_SNP.CORE_GTONE</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_CORE_SNP.EVICT_GTONE">UNC_H_CORE_SNP.EVICT_GTONE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_CORE_SNP.EVICT_GTONE</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_DIR_LOOKUP.SNP">UNC_H_DIR_LOOKUP.SNP</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_DIR_LOOKUP.SNP</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_DIR_LOOKUP.NO_SNP">UNC_H_DIR_LOOKUP.NO_SNP</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_DIR_LOOKUP.NO_SNP</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_DIR_UPDATE.HA">UNC_H_DIR_UPDATE.HA</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_DIR_UPDATE.HA</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_DIR_UPDATE.TOR">UNC_H_DIR_UPDATE.TOR</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_DIR_UPDATE.TOR</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_HITME_HIT.EX_RDS">UNC_H_HITME_HIT.EX_RDS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_HITME_HIT.EX_RDS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_LOOKUP.DATA_READ">UNC_C_LLC_LOOKUP.DATA_READ</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_LOOKUP.DATA_READ</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_LOOKUP.REMOTE_SNOOP">UNC_C_LLC_LOOKUP.REMOTE_SNOOP</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_LOOKUP.REMOTE_SNOOP</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_VICTIMS.TOTAL_M">UNC_C_LLC_VICTIMS.M_STATE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_VICTIMS.TOTAL_M</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_VICTIMS.TOTAL_E">UNC_C_LLC_VICTIMS.E_STATE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_VICTIMS.TOTAL_E</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_VICTIMS.TOTAL_S">UNC_C_LLC_VICTIMS.S_STATE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_VICTIMS.TOTAL_S</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_LLC_VICTIMS.TOTAL_F">UNC_C_LLC_VICTIMS.F_STATE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_LLC_VICTIMS.TOTAL_F</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_MISC.RFO_HIT_S">UNC_H_MISC.RFO_HIT_S</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_MISC.RFO_HIT_S</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.READS">UNC_H_REQUESTS.READS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.READS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.WRITES">UNC_H_REQUESTS.WRITES</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.WRITES</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.READS_LOCAL">UNC_H_REQUESTS.READS_LOCAL</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.READS_LOCAL</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.WRITES_LOCAL">UNC_H_REQUESTS.WRITES_LOCAL</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.WRITES_LOCAL</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.INVITOE_LOCAL">UNC_H_REQUESTS.INVITOE_LOCAL</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.INVITOE_LOCAL</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_REQUESTS.INVITOE_REMOTE">UNC_H_REQUESTS.INVITOE_REMOTE</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_REQUESTS.INVITOE_REMOTE</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_SNOOP_RESP.RSPIFWD">UNC_H_SNOOP_RESP.RSPIFWD</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_SNOOP_RESP.RSPIFWD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_SNOOP_RESP.RSPSFWD">UNC_H_SNOOP_RESP.RSPSFWD</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_SNOOP_RESP.RSPSFWD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_SNOOP_RESP.RSP_FWD_WB">UNC_H_SNOOP_RESP.RSP_FWD_WB</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_SNOOP_RESP.RSP_FWD_WB</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_SNOOP_RESP.RSPCNFLCTS">UNC_H_SNOOP_RESP.RSPCNFLCT</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_SNOOP_RESP.RSPCNFLCTS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA">UNC_C_TOR_INSERTS.IRQ</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_INSERTS.IA</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA">UNC_C_TOR_OCCUPANCY.IRQ</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_OCCUPANCY.IA</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_CLOCKTICKS">UNC_IIO_CLOCKTICKS</span></td>
		<td>Counts clockticks of the 1GHz trafiic controller clock in the IIO unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART0">UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART0</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART0</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART1">UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART1</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART1</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART2">UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART2</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART2</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART3">UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART3</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART3</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART0">UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART0</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART0</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART1">UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART1</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART1</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART2">UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART2</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART2</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART3">UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART3</span></td>
		<td>This event is deprecated. Refer to new event UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART3</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_CLOCKTICKS">UNC_UPI_CLOCKTICKS</span></td>
		<td>Counts clockticks of the fixed frequency clock controlling the Intel&#174; Ultra Path Interconnect (UPI).  This clock runs at1/8th the &#39;GT/s&#39; speed of the UPI link.  For example, a  9.6GT/s  link will have a fixed Frequency of 1.2 Ghz.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_DIRECT_ATTEMPTS.D2C">UNC_UPI_DIRECT_ATTEMPTS.D2C</span></td>
		<td>Counts Data Response (DRS) packets that attempted to go direct to core bypassing the CHA.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_DIRECT_ATTEMPTS.D2U">UNC_UPI_DIRECT_ATTEMPTS.D2K</span></td>
		<td>This event is deprecated. Refer to new event UNC_UPI_DIRECT_ATTEMPTS.D2U</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_L1_POWER_CYCLES">UNC_UPI_L1_POWER_CYCLES</span></td>
		<td>Counts cycles when the Intel&#174; Ultra Path Interconnect (UPI) is in L1 power mode.  L1 is a mode that totally shuts down the UPI link.  Link power states are per link and per direction, so for example the Tx direction could be in one state while Rx was in another, this event only coutns when both links are shutdown.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL0P_POWER_CYCLES">UNC_UPI_RxL0P_POWER_CYCLES</span></td>
		<td>Counts cycles when the the receive side (Rx) of the Intel&#174; Ultra Path Interconnect(UPI) is in L0p power mode. L0p is a mode where we disable 60% of the UPI lanes, decreasing our bandwidth in order to save power.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_BYPASSED.SLOT0">UNC_UPI_RxL_BYPASSED.SLOT0</span></td>
		<td>Counts incoming FLITs (FLow control unITs) which bypassed the slot0 RxQ buffer (Receive Queue) and passed directly to the Egress.  This is a latency optimization, and should generally be the common case.  If this value is less than the number of FLITs transfered, it implies that there was queueing getting onto the ring, and thus the transactions saw higher latency.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_BYPASSED.SLOT1">UNC_UPI_RxL_BYPASSED.SLOT1</span></td>
		<td>Counts incoming FLITs (FLow control unITs) which bypassed the slot1 RxQ buffer  (Receive Queue) and passed directly across the BGF and into the Egress.  This is a latency optimization, and should generally be the common case.  If this value is less than the number of FLITs transfered, it implies that there was queueing getting onto the ring, and thus the transactions saw higher latency.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_BYPASSED.SLOT2">UNC_UPI_RxL_BYPASSED.SLOT2</span></td>
		<td>Counts incoming FLITs (FLow control unITs) whcih bypassed the slot2 RxQ buffer (Receive Queue)  and passed directly to the Egress.  This is a latency optimization, and should generally be the common case.  If this value is less than the number of FLITs transfered, it implies that there was queueing getting onto the ring, and thus the transactions saw higher latency.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_FLITS.ALL_NULL">UNC_UPI_RxL_FLITS.NULL</span></td>
		<td>This event is deprecated. Refer to new event UNC_UPI_RxL_FLITS.ALL_NULL</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL0P_POWER_CYCLES">UNC_UPI_TxL0P_POWER_CYCLES</span></td>
		<td>Counts cycles when the transmit side (Tx) of the Intel&#174; Ultra Path Interconnect(UPI) is in L0p power mode. L0p is a mode where we disable 60% of the UPI lanes, decreasing our bandwidth in order to save power.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_BYPASSED">UNC_UPI_TxL_BYPASSED</span></td>
		<td>Counts incoming FLITs (FLow control unITs) which bypassed the TxL(transmit) FLIT buffer and pass directly out the UPI Link. Generally, when data is transmitted across the Intel&#174; Ultra Path Interconnect (UPI), it will bypass the TxQ and pass directly to the link.  However, the TxQ will be used in L0p (Low Power) mode and (Link Layer Retry) LLR  mode, increasing latency to transfer out to the link.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.DATA">UNC_UPI_TxL_FLITS.DATA</span></td>
		<td>Shows legal flit time (hides impact of L0p and L0c).; Count Data Flits (which consume all slots), but how much to count is based on Slot0-2 mask, so count can be 0-3 depending on which slots are enabled for counting..</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.ALL_NULL">UNC_UPI_TxL_FLITS.NULL</span></td>
		<td>This event is deprecated. Refer to new event UNC_UPI_TxL_FLITS.ALL_NULL</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_BYPASS_M2M_Egress.NOT_TAKEN">UNC_M2M_BYPASS_M2M_Egress.NOT_TAKEN</span></td>
		<td>Counts traffic in which the M2M (Mesh to Memory) to iMC (Memory Controller) bypass was not taken</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2CORE_NOT_TAKEN_DIRSTATE">UNC_M2M_DIRECT2CORE_NOT_TAKEN_DIRSTATE</span></td>
		<td>Counts cycles when direct to core mode (which bypasses the CHA) was disabled</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2CORE_TAKEN">UNC_M2M_DIRECT2CORE_TAKEN</span></td>
		<td>Counts when messages were sent direct to core (bypassing the CHA)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2CORE_TXN_OVERRIDE">UNC_M2M_DIRECT2CORE_TXN_OVERRIDE</span></td>
		<td>Counts reads in which direct to core transactions (which would have bypassed the CHA) were overridden</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_LOOKUP.ANY">UNC_M2M_DIRECTORY_LOOKUP.ANY</span></td>
		<td>Counts when the M2M (Mesh to Memory) looks into the multi-socket cacheline Directory state, and found the cacheline marked in Any State (A, I, S or unused)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_LOOKUP.STATE_I">UNC_M2M_DIRECTORY_LOOKUP.STATE_I</span></td>
		<td>Counts when the M2M (Mesh to Memory) looks into the multi-socket cacheline Directory state , and found the cacheline marked in the I (Invalid) state indicating the cacheline is not stored in another socket, and so there is no need to snoop the other sockets for the latest data.  The data may be stored in any state in the local socket.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_LOOKUP.STATE_S">UNC_M2M_DIRECTORY_LOOKUP.STATE_S</span></td>
		<td>Counts when the M2M (Mesh to Memory) looks into the multi-socket cacheline Directory state , and found the cacheline marked in the S (Shared) state indicating the cacheline is either stored in another socket in the S(hared) state , and so there is no need to snoop the other sockets for the latest data.  The data may be stored in any state in the local socket.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_LOOKUP.STATE_A">UNC_M2M_DIRECTORY_LOOKUP.STATE_A</span></td>
		<td>Counts when the M2M (Mesh to Memory) looks into the multi-socket cacheline Directory state, and found the cacheline marked in the A (SnoopAll) state, indicating the cacheline is stored in another socket in any state, and we must snoop the other sockets to make sure we get the latest data.  The data may be stored in any state in the local socket.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.ANY">UNC_M2M_DIRECTORY_UPDATE.ANY</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory to a new state</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.I2S">UNC_M2M_DIRECTORY_UPDATE.I2S</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from I (Invalid) to S (Shared)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.I2A">UNC_M2M_DIRECTORY_UPDATE.I2A</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from I (Invalid) to A (SnoopAll)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.S2I">UNC_M2M_DIRECTORY_UPDATE.S2I</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from S (Shared) to I (Invalid)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.S2A">UNC_M2M_DIRECTORY_UPDATE.S2A</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from S (Shared) to A (SnoopAll)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.A2I">UNC_M2M_DIRECTORY_UPDATE.A2I</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from A (SnoopAll) to I (Invalid)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECTORY_UPDATE.A2S">UNC_M2M_DIRECTORY_UPDATE.A2S</span></td>
		<td>Counts when the M2M (Mesh to Memory) updates the multi-socket cacheline Directory state from from A (SnoopAll) to S (Shared)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_IMC_READS.NORMAL">UNC_M2M_IMC_READS.NORMAL</span></td>
		<td>Counts when the M2M (Mesh to Memory) issues reads to the iMC (Memory Controller).  It only counts  normal priority non-isochronous reads.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_IMC_READS.ALL">UNC_M2M_IMC_READS.ALL</span></td>
		<td>Counts when the M2M (Mesh to Memory) issues reads to the iMC (Memory Controller). </td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_IMC_WRITES.PARTIAL">UNC_M2M_IMC_WRITES.PARTIAL</span></td>
		<td>Counts when the M2M (Mesh to Memory) issues partial writes to the iMC (Memory Controller).  It only counts normal priority non-isochronous writes.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_IMC_WRITES.ALL">UNC_M2M_IMC_WRITES.ALL</span></td>
		<td>Counts when the M2M (Mesh to Memory) issues writes to the iMC (Memory Controller).</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_IMC_WRITES.NI">UNC_M2M_IMC_WRITES.NI</span></td>
		<td>M2M Writes Issued to iMC; All, regardless of priority.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_PREFCAM_DEMAND_PROMOTIONS">UNC_M2M_PREFCAM_DEMAND_PROMOTIONS</span></td>
		<td>Counts when the M2M (Mesh to Memory) promotes a outstanding request in the prefetch queue due to a subsequent demand read request that entered the M2M with the same address.  Explanatory Side Note: The Prefecth queue is made of CAM (Content Addressable Memory)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_PREFCAM_INSERTS">UNC_M2M_PREFCAM_INSERTS</span></td>
		<td>Counts when the M2M (Mesh to Memory) recieves a prefetch request and inserts it into its outstanding prefetch queue.  Explanatory Side Note: the prefect queue is made from CAM: Content Addressable Memory</td>
	</tr>
	<tr>
		<td><span id="UNC_M_ACT_COUNT.WR">UNC_M_ACT_COUNT.WR</span></td>
		<td>Counts DRAM Page Activate commands sent on this channel due to a write request to the iMC (Memory Controller).  Activate commands are issued to open up a page on the DRAM devices so that it can be read or written to with a CAS (Column Access Select) command.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.RD_REG">UNC_M_CAS_COUNT.RD_REG</span></td>
		<td>Counts CAS (Column Access Select) regular read commands issued to DRAM on a per channel basis.  CAS commands are issued to specify the address to read or write on DRAM, and this event increments for every regular read.  This event only counts regular reads and does not includes underfill reads due to partial write requests.  This event counts whether AutoPrecharge (which closes the DRAM Page automatically after a read/write)  is enabled or not.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.RD_UNDERFILL">UNC_M_CAS_COUNT.RD_UNDERFILL</span></td>
		<td>Counts CAS (Column Access Select) underfill read commands issued to DRAM due to a partial write, on a per channel basis.  CAS commands are issued to specify the address to read or write on DRAM, and this command counts underfill reads.  Partial writes must be completed by first reading in the underfill from DRAM and then merging in the partial write data before writing the full line back to DRAM. This event will generally count about the same as the number of partial writes, but may be slightly less because of partials hitting in the WPQ (due to a previous write request). </td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.RD">UNC_M_CAS_COUNT.RD</span></td>
		<td>Counts all CAS (Column Access Select) read commands issued to DRAM on a per channel basis.  CAS commands are issued to specify the address to read or write on DRAM, and this event increments for every read.  This event includes underfill reads due to partial write requests.  This event counts whether AutoPrecharge (which closes the DRAM Page automatically after a read/write)  is enabled or not.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.WR_WMM">UNC_M_CAS_COUNT.WR_WMM</span></td>
		<td>Counts the total number or DRAM Write CAS commands issued on this channel while in Write-Major-Mode.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.WR">UNC_M_CAS_COUNT.WR</span></td>
		<td>Counts all CAS (Column Address Select) commands issued to DRAM per memory channel.  CAS commands are issued to specify the address to read or write on DRAM, and this event increments for every write. This event counts whether AutoPrecharge (which closes the DRAM Page automatically after a read/write) is enabled or not.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CAS_COUNT.ALL">UNC_M_CAS_COUNT.ALL</span></td>
		<td>Counts all CAS (Column Address Select) commands issued to DRAM per memory channel.  CAS commands are issued to specify the address to read or write on DRAM, so this event increments for every read and write. This event counts whether AutoPrecharge (which closes the DRAM Page automatically after a read/write) is enabled or not.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_CLOCKTICKS">UNC_M_CLOCKTICKS</span></td>
		<td>Counts clockticks of the fixed frequency clock of the memory controller using one of the programmable counters.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_POWER_CHANNEL_PPD">UNC_M_POWER_CHANNEL_PPD</span></td>
		<td>Counts cycles when all the ranks in the channel are in PPD (PreCharge Power Down) mode. If IBT (Input Buffer Terminators)=off is enabled, then this event counts the cycles in PPD mode. If IBT=off is not enabled, then this event counts the number of cycles when being in PPD mode could have been taken advantage of.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_POWER_SELF_REFRESH">UNC_M_POWER_SELF_REFRESH</span></td>
		<td>Counts the number of cycles when the iMC (memory controller) is in self-refresh and has a clock. This happens in some ACPI CPU package C-states for the sleep levels. For example, the PCU (Power Control Unit) may ask the iMC to enter self-refresh even though some of the cores are still processing. One use of this is for Intel? Dynamic Power Technology.  Self-refresh is required during package C3 and C6, but there is no clock in the iMC at this time, so it is not possible to count these cases.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_PRE_COUNT.PAGE_MISS">UNC_M_PRE_COUNT.PAGE_MISS</span></td>
		<td>Counts the number of explicit DRAM Precharge commands sent on this channel as a result of a DRAM page miss. This does not include the implicit precharge commands sent with CAS commands in Auto-Precharge mode. This does not include Precharge commands sent as a result of a page close counter expiration.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_PRE_COUNT.RD">UNC_M_PRE_COUNT.RD</span></td>
		<td>Counts the number of explicit DRAM Precharge commands issued on a per channel basis due to a read, so as to close the previous DRAM page, before opening the requested page. </td>
	</tr>
	<tr>
		<td><span id="UNC_M_RPQ_INSERTS">UNC_M_RPQ_INSERTS</span></td>
		<td>Counts the number of read requests allocated into the Read Pending Queue (RPQ).  This queue is used to schedule reads out to the memory controller and to track the requests.  Requests allocate into the RPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC.  The requests deallocate after the read CAS command has been issued to DRAM.  This event counts both Isochronous and non-Isochronous requests which were issued to the RPQ.    </td>
	</tr>
	<tr>
		<td><span id="UNC_M_RPQ_OCCUPANCY">UNC_M_RPQ_OCCUPANCY</span></td>
		<td>Counts the number of entries in the Read Pending Queue (RPQ) at each cycle.  This can then be used to calculate both the average occupancy of the queue (in conjunction with the number of cycles not empty) and the average latency in the queue (in conjunction with the number of allocations).  The RPQ is used to schedule reads out to the memory controller and to track the requests.  Requests allocate into the RPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC. They deallocate from the RPQ after the CAS command has been issued to memory.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_WPQ_INSERTS">UNC_M_WPQ_INSERTS</span></td>
		<td>Counts the number of writes requests allocated into the Write Pending Queue (WPQ).  The WPQ is used to schedule writes out to the memory controller and to track the requests.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC (Memory Controller).  The write requests deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have &#39;posted&#39; to the iMC.</td>
	</tr>
	<tr>
		<td><span id="UNC_M_WPQ_OCCUPANCY">UNC_M_WPQ_OCCUPANCY</span></td>
		<td>Counts the number of entries in the Write Pending Queue (WPQ) at each cycle.  This can then be used to calculate both the average queue occupancy (in conjunction with the number of cycles not empty) and the average latency (in conjunction with the number of allocations).  The WPQ is used to schedule writes out to the memory controller and to track the requests.  Requests allocate into the WPQ soon after they enter the memory controller, and need credits for an entry in this buffer before being sent from the CHA to the iMC (memory controller).  They deallocate after being issued to DRAM.  Write requests themselves are able to complete (from the perspective of the rest of the system) as soon they have &#39;posted&#39; to the iMC.  This is not to be confused with actually performing the write to DRAM.  Therefore, the average latency for this queue is actually not useful for deconstruction intermediate write latencies.  So, we provide filtering based on if the request has posted or not.  By using the &#39;not posted&#39; filter, we can track how long writes spent in the iMC before completions were sent to the HA.  The &#39;posted&#39; filter, on the other hand, provides information about how much queueing is actually happenning in the iMC for writes before they are actually issued to memory.  High average occupancies will generally coincide with high write major mode counts. Is there a filter of sorts???</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.REM_ALL">UNC_C_TOR_INSERTS.REM_ALL</span></td>
		<td>This event is deprecated. </td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_RxC_AD_INSERTS">UNC_M2M_RxC_AD_INSERTS</span></td>
		<td>Counts when the a new entry is Received(RxC) and then added to the AD (Address Ring) Ingress Queue from the CMS (Common Mesh Stop).  This is generally used for reads, and </td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_RxC_AD_OCCUPANCY">UNC_M2M_RxC_AD_OCCUPANCY</span></td>
		<td>AD Ingress (from CMS) Occupancy</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_RxC_BL_INSERTS">UNC_M2M_RxC_BL_INSERTS</span></td>
		<td>BL Ingress (from CMS) Allocations</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_RxC_BL_OCCUPANCY">UNC_M2M_RxC_BL_OCCUPANCY</span></td>
		<td>BL Ingress (from CMS) Occupancy</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_TxC_AD_INSERTS">UNC_M2M_TxC_AD_INSERTS</span></td>
		<td>AD Egress (to CMS) Allocations</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_TxC_AD_OCCUPANCY">UNC_M2M_TxC_AD_OCCUPANCY</span></td>
		<td>AD Egress (to CMS) Occupancy</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_TxC_BL_INSERTS.ALL">UNC_M2M_TxC_BL_INSERTS.ALL</span></td>
		<td>BL Egress (to CMS) Allocations; All</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_TxC_BL_OCCUPANCY.ALL">UNC_M2M_TxC_BL_OCCUPANCY.ALL</span></td>
		<td>BL Egress (to CMS) Occupancy; All</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_FAST_ASSERTED.HORZ">UNC_C_FAST_ASSERTED</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_FAST_ASSERTED.HORZ</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_RxC_INSERTS.IRQ">UNC_H_RxC_INSERTS.IRQ</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_RxC_INSERTS.IRQ</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_RxC_IRQ1_REJECT.PA_MATCH">UNC_H_RxC_IRQ1_REJECT.PA_MATCH</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_RxC_IRQ1_REJECT.PA_MATCH</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_RxC_OCCUPANCY.IRQ">UNC_H_RxC_OCCUPANCY.IRQ</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_RxC_OCCUPANCY.IRQ</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT">UNC_C_TOR_INSERTS.IRQ_HIT</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_INSERTS.IA_HIT</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS">UNC_C_TOR_INSERTS.IRQ_MISS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_INSERTS.IA_MISS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IO_HIT">UNC_C_TOR_INSERTS.PRQ_HIT</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_INSERTS.IO_HIT</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IO_MISS">UNC_C_TOR_INSERTS.PRQ_MISS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_INSERTS.IO_MISS</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT">UNC_C_TOR_OCCUPANCY.IRQ_HIT</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_OCCUPANCY.IA_HIT</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS">UNC_C_TOR_OCCUPANCY.IRQ_MISS</span></td>
		<td>This event is deprecated. Refer to new event UNC_CHA_TOR_OCCUPANCY.IA_MISS</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_FLITS.NON_DATA">UNC_UPI_RxL_FLITS.NON_DATA</span></td>
		<td>Counts protocol header and credit FLITs  (80 bit FLow control unITs) received from any of the 3 UPI slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.NON_DATA">UNC_UPI_TxL_FLITS.NON_DATA</span></td>
		<td>Counts protocol header and credit FLITs (80 bit FLow control unITs) transmitted across any of the 3 UPI (Ultra Path Interconnect) slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.IDLE">UNC_UPI_TxL_FLITS.IDLE</span></td>
		<td>Counts when the Intel Ultra Path Interconnect(UPI) transmits an idle FLIT(80 bit FLow control unITs).  Every UPI cycle must be sending either data FLITs, protocol/credit FLITs or idle FLITs.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.LLCTRL">UNC_UPI_TxL_FLITS.ALL_NULL</span></td>
		<td>Counts null FLITs (80 bit FLow control unITs) transmitted via any of the 3 Intel&#174; Ulra Path Interconnect (UPI) slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_FLITS.NULL">UNC_UPI_RxL_FLITS.ALL_NULL</span></td>
		<td>Counts null FLITs (80 bit FLow control unITs) received from any of the 3 Intel&#174; Ultra Path Interconnect (UPI) Receive Queue slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.PRQ_HIT">UNC_CHA_TOR_INSERTS.IO_HIT</span></td>
		<td>Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.PRQ_MISS">UNC_CHA_TOR_INSERTS.IO_MISS</span></td>
		<td>Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.LOC_IA">UNC_CHA_TOR_INSERTS.IA</span></td>
		<td>Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.; All locally initiated requests from iA Cores</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.IRQ_HIT">UNC_CHA_TOR_INSERTS.IA_HIT</span></td>
		<td>Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_INSERTS.IRQ_MISS">UNC_CHA_TOR_INSERTS.IA_MISS</span></td>
		<td>TOR Inserts : All requests from iA Cores that Missed the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_OCCUPANCY.LOC_IA">UNC_CHA_TOR_OCCUPANCY.IA</span></td>
		<td>For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.   T; All locally initiated requests from iA Cores</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_OCCUPANCY.IRQ_HIT">UNC_CHA_TOR_OCCUPANCY.IA_HIT</span></td>
		<td>For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.   T</td>
	</tr>
	<tr>
		<td><span id="UNC_C_TOR_OCCUPANCY.IRQ_MISS">UNC_CHA_TOR_OCCUPANCY.IA_MISS</span></td>
		<td>For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.   T</td>
	</tr>
	<tr>
		<td><span id="UNC_H_KTI_CREDIT_OCCUPANCY.VN0_BL_NCS">UNC_CHA_UPI_CREDIT_OCCUPANCY.VN0_BL_NCS</span></td>
		<td>Accumulates the number of UPI credits available in each cycle for either the AD or BL ring.  In order to send snoops, snoop responses, requests, data, etc to the UPI agent on the ring, it is necessary to first acquire a credit for the UPI ingress buffer.  This stat increments by the number of credits that are available each cycle.  This can be used in conjunction with the Credit Acquired event in order to calculate average credit lifetime.  This event supports filtering for the different types of credits that are available.  Note that you must select the link that you would like to monitor using the link select register, and you can only monitor 1 link at a time.</td>
	</tr>
	<tr>
		<td><span id="UNC_M3K_KTI_PREFETCH_SPAWN">UNC_M3UPI_UPI_PREFETCH_SPAWN</span></td>
		<td>Count cases where flow control queue that sits between the Intel&#174; Ultra Path Interconnect (UPI) and the mesh spawns a prefetch to the iMC (Memory Controller)</td>
	</tr>
	<tr>
		<td><span id="UNC_H_HITME_HIT.EX_RDS">UNC_CHA_HITME_HIT.EX_RDS</span></td>
		<td>Counts read requests from a remote socket which hit in the HitME cache (used to cache the multi-socket Directory state) to a line in the E(Exclusive) state.  This includes the following read opcodes (RdCode, RdData, RdDataMigratory, RdCur, RdInv*, Inv*)</td>
	</tr>
	<tr>
		<td><span id="UNC_C_FAST_ASSERTED">UNC_CHA_FAST_ASSERTED.HORZ</span></td>
		<td>Counts the number of cycles either the local or incoming distress signals are asserted.  Incoming distress includes up, dn and across.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_CLOCKTICKS">UNC_CHA_CLOCKTICKS</span></td>
		<td>Counts clockticks of the clock controlling the uncore caching and home agent (CHA).</td>
	</tr>
	<tr>
		<td><span id="UNC_H_CORE_SNP.CORE_GTONE">UNC_CHA_CORE_SNP.CORE_GTONE</span></td>
		<td>Counts the number of transactions that trigger a configurable number of cross snoops.  Cores are snooped if the transaction looks up the cache and determines that it is necessary based on the operation type and what CoreValid bits are set.  For example, if 2 CV bits are set on a data read, the cores must have the data in S state so it is not necessary to snoop them.  However, if only 1 CV bit is set the core my have modified the data.  If the transaction was an RFO, it would need to invalidate the lines.  This event can be filtered based on who triggered the initial snoop(s).</td>
	</tr>
	<tr>
		<td><span id="UNC_H_CORE_SNP.EVICT_GTONE">UNC_CHA_CORE_SNP.EVICT_GTONE</span></td>
		<td>Counts the number of transactions that trigger a configurable number of cross snoops.  Cores are snooped if the transaction looks up the cache and determines that it is necessary based on the operation type and what CoreValid bits are set.  For example, if 2 CV bits are set on a data read, the cores must have the data in S state so it is not necessary to snoop them.  However, if only 1 CV bit is set the core my have modified the data.  If the transaction was an RFO, it would need to invalidate the lines.  This event can be filtered based on who triggered the initial snoop(s).</td>
	</tr>
	<tr>
		<td><span id="UNC_H_DIR_LOOKUP.SNP">UNC_CHA_DIR_LOOKUP.SNP</span></td>
		<td>Counts  transactions that looked into the multi-socket cacheline Directory state, and sent one or more snoops, because the Directory indicated it was needed</td>
	</tr>
	<tr>
		<td><span id="UNC_H_DIR_LOOKUP.NO_SNP">UNC_CHA_DIR_LOOKUP.NO_SNP</span></td>
		<td>Counts transactions that looked into the multi-socket cacheline Directory state, and therefore did not send a snoop because the Directory indicated it was not needed</td>
	</tr>
	<tr>
		<td><span id="UNC_H_DIR_UPDATE.HA">UNC_CHA_DIR_UPDATE.HA</span></td>
		<td>Counts only multi-socket cacheline Directory state updates memory writes issued from the HA pipe. This does not include memory write requests which are for I (Invalid) or E (Exclusive) cachelines.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_DIR_UPDATE.TOR">UNC_CHA_DIR_UPDATE.TOR</span></td>
		<td>Counts only multi-socket cacheline Directory state updates due to memory writes issued from the TOR pipe which are the result of remote transaction hitting the SF/LLC and returning data Core2Core. This does not include memory write requests which are for I (Invalid) or E (Exclusive) cachelines.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_IMC_READS_COUNT.NORMAL">UNC_CHA_IMC_READS_COUNT.NORMAL</span></td>
		<td>Counts when a normal (Non-Isochronous) read is issued to any of the memory controller channels from the CHA.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_IMC_WRITES_COUNT.FULL">UNC_CHA_IMC_WRITES_COUNT.FULL</span></td>
		<td>Counts when a normal (Non-Isochronous) full line write is issued from the CHA to the any of the memory controller channels.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_MISC.RFO_HIT_S">UNC_CHA_MISC.RFO_HIT_S</span></td>
		<td>Counts when a RFO (the Read for Ownership issued before a  write) request hit a cacheline in the S (Shared) state.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.READS">UNC_CHA_REQUESTS.READS</span></td>
		<td>Counts read requests made into this CHA. Reads include all read opcodes (including RFO: the Read for Ownership issued before a  write) .</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.WRITES">UNC_CHA_REQUESTS.WRITES</span></td>
		<td>Counts write requests made into the CHA, including streaming, evictions, HitM (Reads from another core to a Modified cacheline), etc.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.READS_LOCAL">UNC_CHA_REQUESTS.READS_LOCAL</span></td>
		<td>Counts read requests coming from a unit on this socket made into this CHA. Reads include all read opcodes (including RFO: the Read for Ownership issued before a  write).</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.READS_REMOTE">UNC_CHA_REQUESTS.READS_REMOTE</span></td>
		<td>Counts read requests coming from a remote socket made into the CHA. Reads include all read opcodes (including RFO: the Read for Ownership issued before a  write). </td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.WRITES_LOCAL">UNC_CHA_REQUESTS.WRITES_LOCAL</span></td>
		<td>Counts  write requests coming from a unit on this socket made into this CHA, including streaming, evictions, HitM (Reads from another core to a Modified cacheline), etc.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.INVITOE_LOCAL">UNC_CHA_REQUESTS.INVITOE_LOCAL</span></td>
		<td>Counts the total number of requests coming from a unit on this socket for exclusive ownership of a cache line without receiving data (INVITOE) to the CHA.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_REQUESTS.INVITOE_REMOTE">UNC_CHA_REQUESTS.INVITOE_REMOTE</span></td>
		<td>Counts the total number of requests coming from a remote socket for exclusive ownership of a cache line without receiving data (INVITOE) to the CHA.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSPI">UNC_CHA_SNOOP_RESP.RSPI</span></td>
		<td>Counts when a transaction with the opcode type RspI Snoop Response was received which indicates the remote cache does not have the data, or when the remote cache silently evicts data (such as when an RFO: the Read for Ownership issued before a write hits non-modified data).</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSPIFWD">UNC_CHA_SNOOP_RESP.RSPIFWD</span></td>
		<td>Counts when a a transaction with the opcode type RspIFwd Snoop Response was received which indicates a remote caching agent forwarded the data and the requesting agent is able to acquire the data in E (Exclusive) or M (modified) states.  This is commonly returned with RFO (the Read for Ownership issued before a write) transactions.  The snoop could have either been to a cacheline in the M,E,F (Modified, Exclusive or Forward)  states.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSPSFWD">UNC_CHA_SNOOP_RESP.RSPSFWD</span></td>
		<td>Counts when a a transaction with the opcode type RspSFwd Snoop Response was received which indicates a remote caching agent forwarded the data but held on to its current copy.  This is common for data and code reads that hit in a remote socket in E (Exclusive) or F (Forward) state.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSP_WB">UNC_CHA_SNOOP_RESP.RSP_WBWB</span></td>
		<td>Counts when a transaction with the opcode type Rsp*WB Snoop Response was received which indicates which indicates the data was written back to it&#39;s home.  This is returned when a non-RFO request hits a cacheline in the Modified state. The Cache can either downgrade the cacheline to a S (Shared) or I (Invalid) state depending on how the system has been configured.  This reponse will also be sent when a cache requests E (Exclusive) ownership of a cache line without receiving data, because the cache must acquire ownership.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSP_FWD_WB">UNC_CHA_SNOOP_RESP.RSP_FWD_WB</span></td>
		<td>Counts when a transaction with the opcode type Rsp*Fwd*WB Snoop Response was received which indicates the data was written back to it&#39;s home socket, and the cacheline was forwarded to the requestor socket.  This snoop response is only used in &gt;= 4 socket systems.  It is used when a snoop HITM&#39;s in a remote caching agent and it directly forwards data to a requestor, and simultaneously returns data to it&#39;s home socket to be written back to memory.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SNOOP_RESP.RSPCNFLCT">UNC_CHA_SNOOP_RESP.RSPCNFLCTS</span></td>
		<td>Counts when a a transaction with the opcode type RspCnflct* Snoop Response was received. This is returned when a snoop finds an existing outstanding transaction in a remote caching agent. This triggers conflict resolution hardware. This covers both the opcode RspCnflct and RspCnflctWbI.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SF_EVICTION.M_STATE">UNC_CHA_SF_EVICTION.M_STATE</span></td>
		<td>Counts snoop filter capacity evictions for entries tracking modified lines in the cores’ cache.&#160; Snoop filter capacity evictions occur when the snoop filter is full and evicts an existing entry to track a new entry.&#160; Does not count clean evictions such as when a core’s cache replaces a tracked cacheline with a new cacheline.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SF_EVICTION.E_STATE">UNC_CHA_SF_EVICTION.E_STATE</span></td>
		<td>Counts snoop filter capacity evictions for entries tracking exclusive lines in the cores’ cache.&#160; Snoop filter capacity evictions occur when the snoop filter is full and evicts an existing entry to track a new entry.&#160; Does not count clean evictions such as when a core’s cache replaces a tracked cacheline with a new cacheline.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_SF_EVICTION.S_STATE">UNC_CHA_SF_EVICTION.S_STATE</span></td>
		<td>Counts snoop filter capacity evictions for entries tracking shared lines in the cores’ cache.&#160; Snoop filter capacity evictions occur when the snoop filter is full and evicts an existing entry to track a new entry.&#160; Does not count clean evictions such as when a core’s cache replaces a tracked cacheline with a new cacheline.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.REM_ALL">UNC_CHA_TOR_INSERTS.REM_ALL</span></td>
		<td>This event is deprecated. </td>
	</tr>
	<tr>
		<td><span id="UNC_H_RxC_INSERTS.IRQ">UNC_CHA_RxC_INSERTS.IRQ</span></td>
		<td>Counts number of allocations per cycle into the specified Ingress queue.</td>
	</tr>
	<tr>
		<td><span id="UNC_H_RxC_IRQ1_REJECT.PA_MATCH">UNC_CHA_RxC_IRQ1_REJECT.PA_MATCH</span></td>
		<td>Ingress (from CMS) Request Queue Rejects; PhyAddr Match</td>
	</tr>
	<tr>
		<td><span id="UNC_H_RxC_OCCUPANCY.IRQ">UNC_CHA_RxC_OCCUPANCY.IRQ</span></td>
		<td>Counts number of entries in the specified Ingress queue in each cycle.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_WRITE.PART0">UNC_IIO_DATA_REQ_BY_CPU.MEM_WRITE.PART0</span></td>
		<td>Counts every write request of 4 bytes of data made to the MMIO space of a card on IIO Part0 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_WRITE.PART1">UNC_IIO_DATA_REQ_BY_CPU.MEM_WRITE.PART1</span></td>
		<td>Counts every write request of 4 bytes of data made to the MMIO space of a card on IIO Part1 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_WRITE.PART2">UNC_IIO_DATA_REQ_BY_CPU.MEM_WRITE.PART2</span></td>
		<td>Counts every write request of 4 bytes of data made to the MMIO space of a card on IIO Part2 by  a unit on the main die (generally a core) or by another IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_WRITE.PART3">UNC_IIO_DATA_REQ_BY_CPU.MEM_WRITE.PART3</span></td>
		<td>Counts every write request of 4 bytes of data made to the MMIO space of a card on IIO Part3 by  a unit on the main die (generally a core) or by another IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_WRITE.PART0">UNC_IIO_DATA_REQ_BY_CPU.PEER_WRITE.PART0</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made to the MMIO space of a card on IIO Part0 by a different IIO unit. Does not include requests made by the same IIO unit.  In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_WRITE.PART1">UNC_IIO_DATA_REQ_BY_CPU.PEER_WRITE.PART1</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made to the MMIO space of a card on IIO Part1 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_WRITE.PART2">UNC_IIO_DATA_REQ_BY_CPU.PEER_WRITE.PART2</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made to the MMIO space of a card on IIO Part2 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_WRITE.PART3">UNC_IIO_DATA_REQ_BY_CPU.PEER_WRITE.PART3</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made to the MMIO space of a card on IIO Part3 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_READ.PART0">UNC_IIO_DATA_REQ_BY_CPU.MEM_READ.PART0</span></td>
		<td>Counts every read request for 4 bytes of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part0. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_READ.PART1">UNC_IIO_DATA_REQ_BY_CPU.MEM_READ.PART1</span></td>
		<td>Counts every read request for 4 bytes of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part1. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_READ.PART2">UNC_IIO_DATA_REQ_BY_CPU.MEM_READ.PART2</span></td>
		<td>Counts every read request for 4 bytes of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part2. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.MEM_READ.PART3">UNC_IIO_DATA_REQ_BY_CPU.MEM_READ.PART3</span></td>
		<td>Counts every read request for 4 bytes of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part3. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_READ.PART0">UNC_IIO_DATA_REQ_BY_CPU.PEER_READ.PART0</span></td>
		<td>Counts ever peer to peer read request for 4 bytes of data made by a different IIO unit to the MMIO space of a card on IIO Part0. Does not include requests made by the same IIO unit. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_READ.PART1">UNC_IIO_DATA_REQ_BY_CPU.PEER_READ.PART1</span></td>
		<td>Counts ever peer to peer read request for 4 bytes of data made by a different IIO unit to the MMIO space of a card on IIO Part1. Does not include requests made by the same IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_READ.PART2">UNC_IIO_DATA_REQ_BY_CPU.PEER_READ.PART2</span></td>
		<td>Counts ever peer to peer read request for 4 bytes of data made by a different IIO unit to the MMIO space of a card on IIO Part2. Does not include requests made by the same IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_OUT.PEER_READ.PART3">UNC_IIO_DATA_REQ_BY_CPU.PEER_READ.PART3</span></td>
		<td>Counts ever peer to peer read request for 4 bytes of data made by a different IIO unit to the MMIO space of a card on IIO Part3. Does not include requests made by the same IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART0">UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART0</span></td>
		<td>Counts every write request of 4 bytes of data made by IIO Part0 to a unit onthe main die (generally memory). In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART1">UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART1</span></td>
		<td>Counts every write request of 4 bytes of data made by IIO Part1 to a unit on the main die (generally memory). In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART2">UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART2</span></td>
		<td>Counts every write request of 4 bytes of data made by IIO Part2 to a unit on the main die (generally memory). In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_WRITE.PART3">UNC_IIO_DATA_REQ_OF_CPU.MEM_WRITE.PART3</span></td>
		<td>Counts every write request of 4 bytes of data made by IIO Part3 to a unit on the main die (generally memory). In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_WRITE.PART0">UNC_IIO_DATA_REQ_OF_CPU.PEER_WRITE.PART0</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made by IIO Part0 to the MMIO space of an IIO target. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_WRITE.PART1">UNC_IIO_DATA_REQ_OF_CPU.PEER_WRITE.PART1</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made by IIO Part1 to the MMIO space of an IIO target. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_WRITE.PART2">UNC_IIO_DATA_REQ_OF_CPU.PEER_WRITE.PART2</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made by IIO Part2 to the MMIO space of an IIO target. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_WRITE.PART3">UNC_IIO_DATA_REQ_OF_CPU.PEER_WRITE.PART3</span></td>
		<td>Counts every peer to peer write request of 4 bytes of data made by IIO Part3 to the MMIO space of an IIO target. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART0">UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART0</span></td>
		<td>Counts every read request for 4 bytes of data made by IIO Part0 to a unit on the main die (generally memory). In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART1">UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART1</span></td>
		<td>Counts every read request for 4 bytes of data made by IIO Part1 to a unit on the main die (generally memory). In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART2">UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART2</span></td>
		<td>Counts every read request for 4 bytes of data made by IIO Part2 to a unit on the main die (generally memory). In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.MEM_READ.PART3">UNC_IIO_DATA_REQ_OF_CPU.MEM_READ.PART3</span></td>
		<td>Counts every read request for 4 bytes of data made by IIO Part3 to a unit on the main die (generally memory). In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_READ.PART0">UNC_IIO_DATA_REQ_OF_CPU.PEER_READ.PART0</span></td>
		<td>Counts every peer to peer read request for 4 bytes of data made by IIO Part0 to the MMIO space of an IIO target. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_READ.PART1">UNC_IIO_DATA_REQ_OF_CPU.PEER_READ.PART1</span></td>
		<td>Counts every peer to peer read request for 4 bytes of data made by IIO Part1 to the MMIO space of an IIO target. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_READ.PART2">UNC_IIO_DATA_REQ_OF_CPU.PEER_READ.PART2</span></td>
		<td>Counts every peer to peer read request for 4 bytes of data made by IIO Part2 to the MMIO space of an IIO target. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_PAYLOAD_BYTES_IN.PEER_READ.PART3">UNC_IIO_DATA_REQ_OF_CPU.PEER_READ.PART3</span></td>
		<td>Counts every peer to peer read request for 4 bytes of data made by IIO Part3 to the MMIO space of an IIO target. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_WRITE.PART0">UNC_IIO_TXN_REQ_BY_CPU.MEM_WRITE.PART0</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part0 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_WRITE.PART1">UNC_IIO_TXN_REQ_BY_CPU.MEM_WRITE.PART1</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part1 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_WRITE.PART2">UNC_IIO_TXN_REQ_BY_CPU.MEM_WRITE.PART2</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part2 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_WRITE.PART3">UNC_IIO_TXN_REQ_BY_CPU.MEM_WRITE.PART3</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part3 by a unit on the main die (generally a core) or by another IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_WRITE.PART0">UNC_IIO_TXN_REQ_BY_CPU.PEER_WRITE.PART0</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part0 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_WRITE.PART1">UNC_IIO_TXN_REQ_BY_CPU.PEER_WRITE.PART1</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part1 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_WRITE.PART2">UNC_IIO_TXN_REQ_BY_CPU.PEER_WRITE.PART2</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part2 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_WRITE.PART3">UNC_IIO_TXN_REQ_BY_CPU.PEER_WRITE.PART3</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made to the MMIO space of a card on IIO Part3 by a different IIO unit. Does not include requests made by the same IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_READ.PART0">UNC_IIO_TXN_REQ_BY_CPU.MEM_READ.PART0</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part0. In the general case, part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_READ.PART1">UNC_IIO_TXN_REQ_BY_CPU.MEM_READ.PART1</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part1. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_READ.PART2">UNC_IIO_TXN_REQ_BY_CPU.MEM_READ.PART2</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part2. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.MEM_READ.PART3">UNC_IIO_TXN_REQ_BY_CPU.MEM_READ.PART3</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by a unit on the main die (generally a core) or by another IIO unit to the MMIO space of a card on IIO Part3. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_READ.PART0">UNC_IIO_TXN_REQ_BY_CPU.PEER_READ.PART0</span></td>
		<td>Counts every peer to peer read request for up to a 64 byte transaction of data made by a different IIO unit to the MMIO space of a card on IIO Part0. Does not include requests made by the same IIO unit. In the general case, part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_READ.PART1">UNC_IIO_TXN_REQ_BY_CPU.PEER_READ.PART1</span></td>
		<td>Counts every peer to peer read request for up to a 64 byte transaction of data made by a different IIO unit to the MMIO space of a card on IIO Part1. Does not include requests made by the same IIO unit. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_READ.PART2">UNC_IIO_TXN_REQ_BY_CPU.PEER_READ.PART2</span></td>
		<td>Counts every peer to peer read request for up to a 64 byte transaction of data made by a different IIO unit to the MMIO space of a card on IIO Part2. Does not include requests made by the same IIO unit. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_OUT.PEER_READ.PART3">UNC_IIO_TXN_REQ_BY_CPU.PEER_READ.PART3</span></td>
		<td>Counts every peer to peer read request for up to a 64 byte transaction of data made by a different IIO unit to the MMIO space of a card on IIO Part3. Does not include requests made by the same IIO unit. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_RxL_FLITS.DATA">UNC_UPI_RxL_FLITS.ALL_DATA</span></td>
		<td>Counts valid data FLITs  (80 bit FLow control unITs: 64bits of data) received from any of the 3 Intel&#174; Ultra Path Interconnect (UPI) Receive Queue slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_TxL_FLITS.DATA">UNC_UPI_TxL_FLITS.ALL_DATA</span></td>
		<td>Counts valid data FLITs (80 bit FLow control unITs: 64bits of data) transmitted (TxL) via any of the 3 Intel&#174; Ultra Path Interconnect (UPI) slots on this UPI unit.</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2KTI_NOT_TAKEN_CREDITS">UNC_M2M_DIRECT2UPI_NOT_TAKEN_CREDITS</span></td>
		<td>Counts reads in which direct to Intel&#174; Ultra Path Interconnect (UPI) transactions (which would have bypassed the CHA) were overridden</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2KTI_NOT_TAKEN_DIRSTATE">UNC_M2M_DIRECT2UPI_NOT_TAKEN_DIRSTATE</span></td>
		<td>Counts cycles when the ability to send messages direct to the Intel&#174; Ultra Path Interconnect (bypassing the CHA) was disabled</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2KTI_TAKEN">UNC_M2M_DIRECT2UPI_TAKEN</span></td>
		<td>Counts when messages were sent direct to the Intel&#174; Ultra Path Interconnect (bypassing the CHA)</td>
	</tr>
	<tr>
		<td><span id="UNC_M2M_DIRECT2KTI_TXN_OVERRIDE">UNC_M2M_DIRECT2UPI_TXN_OVERRIDE</span></td>
		<td>Counts when a read message that was sent direct to the Intel&#174; Ultra Path Interconnect (bypassing the CHA) was overridden</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_IN.MEM_WRITE.PART0">UNC_IIO_TXN_REQ_OF_CPU.MEM_WRITE.PART0</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made by IIO Part0 to a unit on the main die (generally memory). In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_IN.MEM_WRITE.PART1">UNC_IIO_TXN_REQ_OF_CPU.MEM_WRITE.PART1</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made by IIO Part1 to a unit on the main die (generally memory). In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_IN.MEM_WRITE.PART2">UNC_IIO_TXN_REQ_OF_CPU.MEM_WRITE.PART2</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made by IIO Part2 to a unit on the main die (generally memory). In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_IN.MEM_WRITE.PART3">UNC_IIO_TXN_REQ_OF_CPU.MEM_WRITE.PART3</span></td>
		<td>Counts every write request of up to a 64 byte transaction of data made by IIO Part3 to a unit on the main die (generally memory). In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART0">UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART0</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made by IIO Part0 to the MMIO space of an IIO target. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART1">UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART1</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made by IIO Part1 to the MMIO space of an IIO target.In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART2">UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART2</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made by IIO Part2 to the MMIO space of an IIO target. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART3">UNC_IIO_TXN_REQ_OF_CPU.PEER_WRITE.PART3</span></td>
		<td>Counts every peer to peer write request of up to a 64 byte transaction of data made by IIO Part3 to the MMIO space of an IIO target. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART0">UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART0</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by IIO Part0 to a unit on the main die (generally memory). In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART1">UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART1</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by IIO Part1 to a unit on the main die (generally memory). In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART2">UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART2</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by IIO Part2 to a unit on the main die (generally memory). In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART3">UNC_IIO_TXN_REQ_OF_CPU.MEM_READ.PART3</span></td>
		<td>Counts every read request for up to a 64 byte transaction of data made by IIO Part3 to a unit on the main die (generally memory). In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to  any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART0">UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART0</span></td>
		<td>Counts every peer to peer read request of up to a 64 byte transaction made by IIO Part0 to the MMIO space of an IIO target. In the general case, Part0 refers to a standard PCIe card of any size (x16,x8,x4) that is plugged directly into one of the PCIe slots. Part0 could also refer to any device plugged into the first slot of a PCIe riser card or to a device attached to the IIO unit which starts its use of the bus using lane 0 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART1">UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART1</span></td>
		<td>Counts every peer to peer read request of up to a 64 byte transaction made by IIO Part1 to the MMIO space of an IIO target. In the general case, Part1 refers to a x4 PCIe card plugged into the second slot of a PCIe riser card, but it could refer to any x4 device attached to the IIO unit using lanes starting at lane 4 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART2">UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART2</span></td>
		<td>Counts every peer to peer read request of up to a 64 byte transaction made by IIO Part2 to the MMIO space of an IIO target. In the general case, Part2 refers to a x4 or x8 PCIe card plugged into the third slot of a PCIe riser card, but it could refer to any x4 or x8 device attached to the IIO unit and using lanes starting at lane 8 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART3">UNC_IIO_TXN_REQ_OF_CPU.PEER_READ.PART3</span></td>
		<td>Counts every peer to peer read request of up to a 64 byte transaction made by IIO Part3 to the MMIO space of an IIO target. In the general case, Part3 refers to a x4 PCIe card plugged into the fourth slot of a PCIe riser card, but it could brefer to any device attached to the IIO unit using the lanes starting at lane 12 of the 16 lanes supported by the bus.</td>
	</tr>
	<tr>
		<td><span id="UNC_UPI_DIRECT_ATTEMPTS.D2K">UNC_UPI_DIRECT_ATTEMPTS.D2U</span></td>
		<td>Counts Data Response (DRS) packets that attempted to go direct to Intel&#174; Ultra Path Interconnect (UPI) bypassing the CHA .</td>
	</tr>
	<tr>
		<td><span id="UNC_C_LLC_VICTIMS.M_STATE">UNC_CHA_LLC_VICTIMS.TOTAL_M</span></td>
		<td>Counts the number of lines that were victimized on a fill.  This can be filtered by the state that the line was in.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_LLC_VICTIMS.E_STATE">UNC_CHA_LLC_VICTIMS.TOTAL_E</span></td>
		<td>Counts the number of lines that were victimized on a fill.  This can be filtered by the state that the line was in.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_LLC_VICTIMS.S_STATE">UNC_CHA_LLC_VICTIMS.TOTAL_S</span></td>
		<td>Counts the number of lines that were victimized on a fill.  This can be filtered by the state that the line was in.</td>
	</tr>
	<tr>
		<td><span id="UNC_C_LLC_VICTIMS.F_STATE">UNC_CHA_LLC_VICTIMS.TOTAL_F</span></td>
		<td>Counts the number of lines that were victimized on a fill.  This can be filtered by the state that the line was in.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_DRD">UNC_CHA_TOR_INSERTS.IA_HIT_DRD</span></td>
		<td>TOR Inserts : DRds issued by iA Cores that Hit the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_CRD">UNC_CHA_TOR_INSERTS.IA_HIT_CRD</span></td>
		<td>TOR Inserts : CRds issued by iA Cores that Hit the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_RFO">UNC_CHA_TOR_INSERTS.IA_HIT_RFO</span></td>
		<td>TOR Inserts : RFOs issued by iA Cores that Hit the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefDRD">UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefDRD</span></td>
		<td>UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefDRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefCRD">UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefCRD</span></td>
		<td>UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefCRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefRFO">UNC_CHA_TOR_INSERTS.IA_HIT_LlcPrefRFO</span></td>
		<td>TOR Inserts : LLCPrefRFO issued by iA Cores that hit the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_DRD">UNC_CHA_TOR_INSERTS.IA_MISS_DRD</span></td>
		<td>TOR Inserts : DRds issued by iA Cores that Missed the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_CRD">UNC_CHA_TOR_INSERTS.IA_MISS_CRD</span></td>
		<td>TOR Inserts : CRds issued by iA Cores that Missed the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_RFO">UNC_CHA_TOR_INSERTS.IA_MISS_RFO</span></td>
		<td>TOR Inserts : RFOs issued by iA Cores that Missed the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefDRD">UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefDRD</span></td>
		<td>UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefDRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefCRD">UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefCRD</span></td>
		<td>UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefCRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefRFO">UNC_CHA_TOR_INSERTS.IA_MISS_LlcPrefRFO</span></td>
		<td>TOR Inserts : LLCPrefRFO issued by iA Cores that missed the LLC : Counts the number of entries successfuly inserted into the TOR that match qualifications specified by the subevent.   Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_DRD">UNC_CHA_TOR_OCCUPANCY.IA_HIT_DRD</span></td>
		<td>TOR Occupancy : DRds issued by iA Cores that Hit the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_CRD">UNC_CHA_TOR_OCCUPANCY.IA_HIT_CRD</span></td>
		<td>TOR Occupancy : CRds issued by iA Cores that Hit the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_RFO">UNC_CHA_TOR_OCCUPANCY.IA_HIT_RFO</span></td>
		<td>TOR Occupancy : RFOs issued by iA Cores that Hit the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefDRD">UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefDRD</span></td>
		<td>UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefDRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefCRD">UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefCRD</span></td>
		<td>UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefCRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefRFO">UNC_CHA_TOR_OCCUPANCY.IA_HIT_LlcPrefRFO</span></td>
		<td>TOR Occupancy : LLCPrefRFO issued by iA Cores that hit the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_DRD">UNC_CHA_TOR_OCCUPANCY.IA_MISS_DRD</span></td>
		<td>TOR Occupancy : DRds issued by iA Cores that Missed the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_CRD">UNC_CHA_TOR_OCCUPANCY.IA_MISS_CRD</span></td>
		<td>TOR Occupancy : CRds issued by iA Cores that Missed the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_RFO">UNC_CHA_TOR_OCCUPANCY.IA_MISS_RFO</span></td>
		<td>TOR Occupancy : RFOs issued by iA Cores that Missed the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefDRD">UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefDRD</span></td>
		<td>UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefDRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefCRD">UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefCRD</span></td>
		<td>UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefCRD</td>
	</tr>
	<tr>
		<td><span id="UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefRFO">UNC_CHA_TOR_OCCUPANCY.IA_MISS_LlcPrefRFO</span></td>
		<td>TOR Occupancy : LLCPrefRFO issued by iA Cores that missed the LLC : For each cycle, this event accumulates the number of valid entries in the TOR that match qualifications specified by the subevent.     Does not include addressless requests such as locks and interrupts.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=ANY_RESPONSE</span></td>
		<td>Counts demand data reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts demand data reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts demand data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts demand data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts demand data reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts demand data reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts demand data reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts demand data reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts demand data reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts demand data reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts demand data reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=DEMAND_RFO: response=ANY_RESPONSE</span></td>
		<td>Counts all demand data writes (RFOs) that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all demand data writes (RFOs) that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all demand data writes (RFOs) that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all demand data writes (RFOs) that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all demand data writes (RFOs) that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all demand data writes (RFOs) that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all demand data writes (RFOs) that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all demand data writes (RFOs) that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand data writes (RFOs) that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand data writes (RFOs) that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand data writes (RFOs) that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=ANY_RESPONSE</span></td>
		<td>Counts all demand code reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all demand code reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all demand code reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all demand code reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all demand code reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all demand code reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all demand code reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all demand code reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand code reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand code reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand code reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=ANY_RESPONSE</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch (that bring data to L2) data reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=PF_L2_RFO: response=ANY_RESPONSE</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to L2) RFOs that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=ANY_RESPONSE</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) data reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=PF_L3_RFO: response=ANY_RESPONSE</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch (that bring data to LLC only) RFOs that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=ANY_RESPONSE</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts L1 data cache hardware prefetch requests and software prefetch requests that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=ANY_RESPONSE</span></td>
		<td>Counts all prefetch data reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all prefetch data reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all prefetch data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all prefetch data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all prefetch data reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all prefetch data reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all prefetch data reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all prefetch data reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch data reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch data reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all prefetch data reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=ANY_RESPONSE</span></td>
		<td>Counts prefetch RFOs that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts prefetch RFOs that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts prefetch RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts prefetch RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts prefetch RFOs that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts prefetch RFOs that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts prefetch RFOs that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts prefetch RFOs that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch RFOs that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch RFOs that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts prefetch RFOs that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=ANY_RESPONSE</span></td>
		<td>Counts all demand &amp; prefetch data reads that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all demand &amp; prefetch data reads that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all demand &amp; prefetch data reads that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all demand &amp; prefetch data reads that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch data reads that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:ANY_RESPONSE">OFFCORE_RESPONSE:request=ALL_RFO: response=ANY_RESPONSE</span></td>
		<td>Counts all demand &amp; prefetch RFOs that have any response type.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_HIT.NO_SNOOP_NEEDED">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.NO_SNOOP_NEEDED</span></td>
		<td>Counts all demand &amp; prefetch RFOs that hit in the L3 and sibling core snoops are not needed as either the core-valid bit is not set or the shared line is present in multiple cores.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_HIT.HIT_OTHER_CORE_NO_FWD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.HIT_OTHER_CORE_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_HIT.HITM_OTHER_CORE">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.HITM_OTHER_CORE</span></td>
		<td>Counts all demand &amp; prefetch RFOs that hit in the L3 and the snoop to one of the sibling cores hits the line in M state and the line is forwarded.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_HIT.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.ANY_SNOOP</span></td>
		<td>Counts all demand &amp; prefetch RFOs that hit in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS.ANY_SNOOP">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS.ANY_SNOOP</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss in the L3.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS.REMOTE_HIT_FORWARD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS.REMOTE_HIT_FORWARD</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss the L3 and clean or shared data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS.REMOTE_HITM">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS.REMOTE_HITM</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss the L3 and the modified data is transferred from remote cache.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss the L3 and the data is returned from local or remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS_REMOTE_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss the L3 and the data is returned from remote dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_MISS_LOCAL_DRAM.SNOOP_MISS_OR_NO_FWD</span></td>
		<td>Counts all demand &amp; prefetch RFOs that miss the L3 and the data is returned from local dram.</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_DATA_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=DEMAND_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_RFO:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=DEMAND_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:DEMAND_CODE_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=DEMAND_CODE_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_DATA_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=PF_L2_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L2_RFO:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=PF_L2_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_DATA_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=PF_L3_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L3_RFO:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=PF_L3_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:PF_L1D_AND_SW:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=PF_L1D_AND_SW: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_DATA_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=ALL_PF_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_PF_RFO:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=ALL_PF_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_DATA_RD:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=ALL_DATA_RD: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
	<tr>
		<td><span id="OFFCORE_RESPONSE:request:ALL_RFO:response:L3_HIT.SNOOP_HIT_WITH_FWD">OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</span></td>
		<td>OFFCORE_RESPONSE:request=ALL_RFO: response=L3_HIT.SNOOP_HIT_WITH_FWD</td>
	</tr>
</table>

</body>
</html>
